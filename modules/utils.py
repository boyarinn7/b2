import os
import hashlib
import json
import base64
import inspect

try:
    import boto3
    from botocore.exceptions import ClientError
except ImportError:
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è boto3 (–º–æ–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ pass –∏–ª–∏ print)
    pass
# –í–æ–∑–º–æ–∂–Ω–æ, –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è ensure_directory_exists –∏–∑ —ç—Ç–æ–≥–æ –∂–µ —Ñ–∞–π–ª–∞ utils?
# from . import ensure_directory_exists # –ï—Å–ª–∏ –æ–Ω–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∑–¥–µ—Å—å –∂–µ
# –ò–ª–∏ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å logger –∫–∞–∫ –∞—Ä–≥—É–º–µ–Ω—Ç, –µ—Å–ª–∏ –æ–Ω –Ω–µ –≥–ª–æ–±–∞–ª—å–Ω—ã–π

from datetime import datetime
from modules.error_handler import handle_error
from modules.logger import get_logger

logger = get_logger("utils")

CONFIG_PATH = "config/config.json"

# --- –ò–ó–ú–ï–ù–ï–ù–ù–ê–Ø –§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ ID ---
def generate_file_id():
    """–°–æ–∑–¥–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –ì–ì–ì–ì–ú–ú–î–î-–ß–ß–ú–ú (–ë–ï–ó .json)."""
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º UTC –¥–ª—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏
    now = datetime.utcnow()
    # –§–æ—Ä–º–∞—Ç –ì–ì–ì–ì–ú–ú–î–î-–ß–ß–ú–ú
    date_part = now.strftime("%Y%m%d")
    time_part = now.strftime("%H%M")
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º ID –ë–ï–ó —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è .json
    return f"{date_part}-{time_part}"


def load_config():
    with open(CONFIG_PATH, "r", encoding="utf-8") as f:
        return json.load(f)

config = load_config()

def load_topics_tracker():
    tracker_path = config["FILE_PATHS"]["topics_tracker"]
    if os.path.exists(tracker_path):
        try:
            with open(tracker_path, "r", encoding="utf-8") as file:
                return json.load(file)
        except json.JSONDecodeError:
            return {}
    return {}

def save_topics_tracker(tracker):
    tracker_path = config["FILE_PATHS"]["topics_tracker"]
    os.makedirs(os.path.dirname(tracker_path), exist_ok=True)
    with open(tracker_path, "w", encoding="utf-8") as file:
        json.dump(tracker, file, ensure_ascii=False, indent=4)

def calculate_file_hash(file_path):
    try:
        with open(file_path, 'rb') as f:
            return hashlib.md5(f.read()).hexdigest()
    except FileNotFoundError:
        handle_error("File Hash Calculation Error", f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
    except Exception as e:
        handle_error("File Hash Calculation Error", e)

def validate_json_structure(data, required_keys):
    missing_keys = [key for key in required_keys if key not in data]
    if missing_keys:
        handle_error("JSON Validation Error", f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–ª—é—á–∏: {missing_keys}")

def ensure_directory_exists(path):
    try:
        os.makedirs(path, exist_ok=True)
    except Exception as e:
        handle_error("Directory Creation Error", e)

def encode_image_to_base64(image_path: str) -> str:
    try:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode("utf-8")
    except FileNotFoundError:
        handle_error("Image Encoding Error", f"–§–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω: {image_path}")
    except Exception as e:
        handle_error("Image Encoding Error", e)

def list_files_in_folder(s3, folder):
    try:
        objects = s3.list_objects_v2(Bucket="boyarinnbotbucket", Prefix=folder)
        return [obj["Key"] for obj in objects.get("Contents", [])]
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤ –≤ {folder}: {e}")
        return []

def is_folder_empty(s3, bucket_name, folder_prefix):
    try:
        response = s3.list_objects_v2(Bucket=bucket_name, Prefix=folder_prefix)
        return "Contents" not in response
    except Exception as e:
        handle_error("B2 Folder Check Error", e)

def load_config_public(config_path):
    if os.path.exists(config_path):
        with open(config_path, 'r', encoding='utf-8') as file:
            return json.load(file)
    return {}

def save_config_public(config_path, config_data):
    with open(config_path, 'w', encoding='utf-8') as file:
        json.dump(config_data, file, indent=4, ensure_ascii=False)

def move_to_archive(s3, bucket_name, generation_id, logger):
    logger.info(f"üõ† –ü—Ä–æ–≤–µ—Ä–∫–∞ s3 –≤ {__file__}, —Å—Ç—Ä–æ–∫–∞ {inspect.currentframe().f_lineno}: {type(s3)}")
    logger.info(f"üõ† –ü–µ—Ä–µ–¥ –≤—ã–∑–æ–≤–æ–º move_to_archive(): s3={type(s3)}")
    archive_folder = f"archive/{generation_id}/"
    source_folder = f"generated/{generation_id}/"
    try:
        objects = s3.list_objects_v2(Bucket=bucket_name, Prefix=source_folder)
        if "Contents" in objects:
            for obj in objects["Contents"]:
                old_key = obj["Key"]
                new_key = old_key.replace(source_folder, archive_folder, 1)
                s3.copy_object(Bucket=bucket_name, CopySource={"Bucket": bucket_name, "Key": old_key}, Key=new_key)
                s3.delete_object(Bucket=bucket_name, Key=old_key)
                logger.info(f"üìÅ –§–∞–π–ª {old_key} –ø–µ—Ä–µ–º–µ—â—ë–Ω –≤ {new_key}")
    except Exception as e:
        handle_error(logger, "–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è –≤ –∞—Ä—Ö–∏–≤", e)
    config_data = load_config_public(s3)  # –û—à–∏–±–∫–∞, –Ω—É–∂–Ω–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –ø–æ–∑–∂–µ
    if "generation_id" in config_data and generation_id in config_data["generation_id"]:
        config_data["generation_id"].remove(generation_id)
        save_config_public(s3, config_data)  # –û—à–∏–±–∫–∞, –Ω—É–∂–Ω–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –ø–æ–∑–∂–µ
        logger.info(f"üóëÔ∏è –£–¥–∞–ª—ë–Ω generation_id {generation_id} –∏–∑ config_public.json")

def load_from_b2(b2_client, b2_path, local_path):
    bucket_name = os.getenv("B2_BUCKET_NAME")
    if not bucket_name:
        raise ValueError("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è B2_BUCKET_NAME –Ω–µ –∑–∞–¥–∞–Ω–∞")
    try:
        os.makedirs(os.path.dirname(local_path), exist_ok=True)
        b2_client.download_file(bucket_name, b2_path, local_path)
        with open(local_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª –∏–∑ B2: {b2_path} -> {local_path}, —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ: {json.dumps(data, ensure_ascii=False)}")
        return data
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ B2 {b2_path}: {e}")
        raise

def save_to_b2(b2_client, data, b2_path, local_path):
    bucket_name = os.getenv("B2_BUCKET_NAME")
    if not bucket_name:
        raise ValueError("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è B2_BUCKET_NAME –Ω–µ –∑–∞–¥–∞–Ω–∞")
    try:
        os.makedirs(os.path.dirname(local_path), exist_ok=True)
        with open(local_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
        b2_client.upload_file(local_path, bucket_name, b2_path)
        logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ B2: {b2_path}, —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ: {json.dumps(data, ensure_ascii=False)}")
        os.remove(local_path)
        logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {local_path}")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ B2 {b2_path}: {e}")
        raise

def load_b2_json(client, bucket, remote_path, local_path, default_value=None):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç JSON –∏–∑ B2, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç default_value –ø—Ä–∏ –æ—à–∏–±–∫–µ –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏."""
    # default_value=None –ª—É—á—à–µ, —á–µ–º {}, —á—Ç–æ–±—ã —Ä–∞–∑–ª–∏—á–∞—Ç—å –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª –∏ –µ–≥–æ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ
    try:
        logger.debug(f"–ó–∞–≥—Ä—É–∑–∫–∞ {remote_path} –∏–∑ B2 –≤ {local_path}")
        client.download_file(bucket, remote_path, local_path)
        if os.path.getsize(local_path) > 0:
            with open(local_path, 'r', encoding='utf-8') as f:
                content = json.load(f)
        else:
            logger.warning(f"–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {local_path} ({remote_path}) –ø—É—Å—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
            content = default_value
        logger.info(f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –∏ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω {remote_path} –∏–∑ B2.")
        return content
    except ClientError as e:
        if e.response['Error']['Code'] == 'NoSuchKey':
            logger.warning(f"{remote_path} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ B2. –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
        else:
            logger.error(f"–û—à–∏–±–∫–∞ B2 –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {remote_path}: {e}")
        return default_value
    except json.JSONDecodeError as json_err:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –∏–∑ {local_path} ({remote_path}): {json_err}. –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
        return default_value
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {remote_path}: {e}")
        return default_value # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ—Ñ–æ–ª—Ç, —á—Ç–æ–±—ã –Ω–µ —É–ø–∞—Å—Ç—å —Å—Ä–∞–∑—É
    finally:
        if os.path.exists(local_path):
            try: os.remove(local_path)
            except OSError: logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {local_path}")

def save_b2_json(client, bucket, remote_path, local_path, data):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ª–æ–≤–∞—Ä—å data –∫–∞–∫ JSON –≤ B2."""
    try:
        logger.debug(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ {remote_path} –≤ B2 —á–µ—Ä–µ–∑ {local_path}")
        with open(local_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
        client.upload_file(local_path, bucket, remote_path)
        logger.info(f"–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {remote_path} –≤ B2: {json.dumps(data, ensure_ascii=False)}") # –õ–æ–≥–∏—Ä—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        return True
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è {remote_path}: {e}")
        return False
    finally:
        if os.path.exists(local_path):
            try: os.remove(local_path)
            except OSError: logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {local_path}")

# --- –§—É–Ω–∫—Ü–∏–∏ –∏–∑ —Å—Ç–∞—Ä–æ–≥–æ –∫–æ–¥–∞ (—Å–ª–µ–≥–∫–∞ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω—ã) ---
# –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ B2_BUCKET_NAME –¥–æ—Å—Ç—É–ø–µ–Ω –≥–ª–æ–±–∞–ª—å–Ω–æ –∏–ª–∏ –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –∫–∞–∫ –∞—Ä–≥—É–º–µ–Ω—Ç


def upload_to_b2(client, bucket_name, target_folder, local_file_path, base_id):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –≤ —É–∫–∞–∑–∞–Ω–Ω—É—é –ø–∞–ø–∫—É B2,
    —Ñ–æ—Ä–º–∏—Ä—É—è –∏–º—è —Ñ–∞–π–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ base_id –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –ø—Ä–∏ —É—Å–ø–µ—Ö–µ, False –ø—Ä–∏ –æ—à–∏–±–∫–µ.
    """
    if not os.path.exists(local_file_path):
        logger.error(f"–õ–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª {local_file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ B2.")
        return False

    # –£–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∏–∑ base_id –ø–µ—Ä–µ–¥ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –Ω–æ–≤–æ–≥–æ
    clean_base_id = base_id.replace(".json", "")
    # –ü–æ–ª—É—á–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    file_extension = os.path.splitext(local_file_path)[1]
    if not file_extension:
         logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –¥–ª—è —Ñ–∞–π–ª–∞ {local_file_path}")
         return False

    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–ª—é—á B2: –Ω–∞–ø—Ä–∏–º–µ—Ä, 666/20250415-0102.png
    s3_key = f"{target_folder.rstrip('/')}/{clean_base_id}{file_extension}"

    logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ {local_file_path} –≤ B2 –∫–∞–∫ {s3_key}...")
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π bucket_name
        client.upload_file(local_file_path, bucket_name, s3_key)
        logger.info(f"‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ B2: {s3_key}")
        return True
    except Exception as e:
        # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º False
        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {local_file_path} –≤ B2 –∫–∞–∫ {s3_key}: {e}")
        return False
# --- –ö–æ–Ω–µ—Ü –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ modules/utils.py ---
