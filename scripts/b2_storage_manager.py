import os
import json
import logging
import subprocess  # –î–ª—è –∑–∞–ø—É—Å–∫–∞ –≤–Ω–µ—à–Ω–∏—Ö —Å–∫—Ä–∏–ø—Ç–æ–≤
import re

from modules.utils import is_folder_empty, ensure_directory_exists, move_to_archive
from scripts.generate_media import download_file_from_b2, generate_mock_video, update_config_public, upload_to_b2
from botocore.exceptions import ClientError
from modules.api_clients import get_b2_client
from modules.logger import get_logger
from modules.error_handler import handle_error
from modules.config_manager import ConfigManager

# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ===
config = ConfigManager()
logger = get_logger("b2_storage_manager")

# === –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ===
B2_BUCKET_NAME = config.get('API_KEYS.b2.bucket_name')
CONFIG_PUBLIC_PATH = config.get('FILE_PATHS.config_public')  # –Ω–∞–ø—Ä–∏–º–µ—Ä, "config/config_public.json"
CONFIG_GEN_PATH = os.path.abspath('config/config_gen.json')
CONFIG_PUBLIC_REMOTE_PATH = "config/config_public.json"  # –∫–ª—é—á –≤ B2
CONFIG_PUBLIC_LOCAL_PATH = os.path.abspath('config_public.json')
FILE_EXTENSIONS = ['.json', '.png', '.mp4']
FOLDERS = [
    config.get('FILE_PATHS.folder_444'),
    config.get('FILE_PATHS.folder_555'),
    config.get('FILE_PATHS.folder_666')
]
ARCHIVE_FOLDER = config.get('FILE_PATHS.archive_folder')

# –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–æ—Ä–º–∞—Ç–∞ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
FILE_NAME_PATTERN = re.compile(r"^\d{8}-\d{4}\.\w+$")


def log_folders_state(s3, folders, stage):
    logger.info(f"\nüìÇ –°–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∞–ø–æ–∫ ({stage}):")
    for folder in folders:
        files = list_files_in_folder(s3, folder)
        logger.info(f"- {folder}: {files}")


def load_config_public(s3):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç config_public.json –∏–∑ B2 –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–∞–∫ —Å–ª–æ–≤–∞—Ä—å.
    """
    try:
        local_path = CONFIG_PUBLIC_LOCAL_PATH
        logger.info(f"üîç s3 –ø–µ—Ä–µ–¥ .download_file(): {type(s3)}")
        s3.download_file(B2_BUCKET_NAME, CONFIG_PUBLIC_REMOTE_PATH, local_path)
        with open(local_path, 'r', encoding='utf-8') as file:
            config_data = json.load(file)
            logger.info(f"‚úÖ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ config_public.json: {config_data}")
            return config_data
    except FileNotFoundError:
        logger.error("‚ùå –§–∞–π–ª config_public.json –Ω–µ –Ω–∞–π–¥–µ–Ω –ª–æ–∫–∞–ª—å–Ω–æ.")
        return {}
    except ClientError as e:
        logger.error(f"Error loading config_public.json: {e.response['Error']['Message']}")
        return {}


def save_config_public(s3, data):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ config_public.json –ª–æ–∫–∞–ª—å–Ω–æ –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –µ–≥–æ –≤ B2.
    """
    try:
        with open(CONFIG_PUBLIC_LOCAL_PATH, 'w', encoding='utf-8') as file:
            json.dump(data, file, ensure_ascii=False, indent=4)
        s3.upload_file(CONFIG_PUBLIC_LOCAL_PATH, B2_BUCKET_NAME, CONFIG_PUBLIC_REMOTE_PATH)
    except Exception as e:
        logger.error(f"Error saving config_public.json: {e}")


def list_files_in_folder(s3, folder_prefix):
    try:
        response = s3.list_objects_v2(Bucket=B2_BUCKET_NAME, Prefix=folder_prefix)
        return [
            obj['Key'] for obj in response.get('Contents', [])
            if obj['Key'] != folder_prefix and not obj['Key'].endswith('.bzEmpty') and FILE_NAME_PATTERN.match(os.path.basename(obj['Key']))
        ]
    except ClientError as e:
        logger.error(f"Error listing files in {folder_prefix}: {e.response['Error']['Message']}")
        return []


def get_ready_groups(files):
    groups = {}
    for file_key in files:
        base_name = os.path.basename(file_key)
        if FILE_NAME_PATTERN.match(base_name):
            group_id = base_name.rsplit('.', 1)[0]
            groups.setdefault(group_id, []).append(base_name)
    ready_groups = []
    for group_id, file_list in groups.items():
        expected_files = [group_id + ext for ext in FILE_EXTENSIONS]
        if all(file in file_list for file in expected_files):
            ready_groups.append(group_id)
    return ready_groups


def handle_publish(s3, config_data):
    """
    –ü–µ—Ä–µ–º–µ—â–∞–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º–∏ generation_id –≤ –∞—Ä—Ö–∏–≤ B2, –ø–æ–∫–∞ —Å–ø–∏—Å–æ–∫ –Ω–µ —Å—Ç–∞–Ω–µ—Ç –ø—É—Å—Ç—ã–º.
    –ü–µ—Ä–µ–±–∏—Ä–∞–µ—Ç –ø–∞–ø–∫–∏ ["444/", "555/", "666/"], –∏—â–µ—Ç —Ñ–∞–π–ª—ã, –≥–¥–µ 'generation_id' –≤—Ö–æ–¥–∏—Ç
    –≤ –∏–º—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, '444/20250201-1131.json') –∏ –∫–æ–ø–∏—Ä—É–µ—Ç –∏—Ö –≤ 'data/archive/'.
    –ü–æ—Å–ª–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è ‚Äî —É–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª—ã –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–π –ø–∞–ø–∫–∏, –∞ –∏–∑ config_public.json
    ‚Äî —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π generation_id.
    """

    while True:
        generation_ids = config_data.get("generation_id", [])
        # –ï—Å–ª–∏ –≤–æ–æ–±—â–µ –Ω–µ—Ç generation_id, –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞—Ç—å –Ω–µ—á–µ–≥–æ
        if not generation_ids:
            logger.info("üìÇ –ù–µ—Ç generation_id –≤ config_public.json, –ø—É–±–ª–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
            return

        # –ï—Å–ª–∏ –∫—Ç–æ-—Ç–æ –∑–∞–ø–∏—Å–∞–ª —Å—Ç—Ä–æ–∫—É –≤–º–µ—Å—Ç–æ —Å–ø–∏—Å–∫–∞ ‚Äî –ø—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤ —Å–ø–∏—Å–æ–∫
        if isinstance(generation_ids, str):
            generation_ids = [generation_ids]

        logger.info(f"üìÇ –ù–∞–π–¥–µ–Ω—ã generation_id: {generation_ids}, –ø–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–∞–π–ª—ã –≤ –∞—Ä—Ö–∏–≤...")

        # –ü–∞–ø–∫–∏, —Å—Ä–µ–¥–∏ –∫–æ—Ç–æ—Ä—ã—Ö –∏—â–µ–º —Ñ–∞–π–ª—ã
        source_folders = ["444/", "555/", "666/"]
        archived_ids = []

        for generation_id in generation_ids:
            for folder in source_folders:
                # –ë–µ—Ä—ë–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ
                files_to_move = list_files_in_folder(s3, folder)
                for file_key in files_to_move:
                    # –ò—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ generation_id
                    if generation_id in file_key:
                        archive_path = f"data/archive/{os.path.basename(file_key)}"
                        try:
                            # –ö–æ–ø–∏—Ä—É–µ–º –≤ –∞—Ä—Ö–∏–≤
                            s3.copy_object(
                                Bucket=B2_BUCKET_NAME,
                                CopySource={"Bucket": B2_BUCKET_NAME, "Key": file_key},
                                Key=archive_path
                            )
                            # –£–¥–∞–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω–∏–∫
                            s3.delete_object(Bucket=B2_BUCKET_NAME, Key=file_key)
                            logger.info(f"‚úÖ –§–∞–π–ª {file_key} –ø–µ—Ä–µ–º–µ—â—ë–Ω –≤ –∞—Ä—Ö–∏–≤: {archive_path}")

                            # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º, —á—Ç–æ —ç—Ç–æ—Ç gen_id —É–∂–µ –∑–∞–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω (—É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–Ω–µ—Å–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ñ–∞–π–ª)
                            if generation_id not in archived_ids:
                                archived_ids.append(generation_id)

                        except ClientError as e:
                            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–∏ {file_key}: {e.response['Error']['Message']}")

        # –£–±–∏—Ä–∞–µ–º –∏–∑ config_public –≤—Å–µ gen_id, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω—ã
        config_data["generation_id"] = [gid for gid in generation_ids if gid not in archived_ids]
        if not config_data["generation_id"]:
            del config_data["generation_id"]  # –ï—Å–ª–∏ –ø—É—Å—Ç, –º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å –∫–ª—é—á

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª—ë–Ω–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        save_config_public(s3, config_data)
        logger.info(f"‚úÖ –ê—Ä—Ö–∏–≤–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è: {archived_ids}")

        # –ï—Å–ª–∏ –±–æ–ª—å—à–µ –Ω–µ—Ç generation_id, –∑–Ω–∞—á–∏—Ç –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞—Ç—å –Ω–µ—á–µ–≥–æ, –≤—ã—Ö–æ–¥–∏–º
        if not config_data.get("generation_id"):
            logger.info("üéâ –í—Å–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ –≥—Ä—É–ø–ø—ã –∑–∞–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω—ã, –∑–∞–≤–µ—Ä—à–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å.")
            break


def move_group(s3, src_folder, dst_folder, group_id):
    for ext in FILE_EXTENSIONS:
        src_key = f"{src_folder}{group_id}{ext}"
        dst_key = f"{dst_folder}{group_id}{ext}"
        try:
            s3.head_object(Bucket=B2_BUCKET_NAME, Key=src_key)
            s3.copy_object(Bucket=B2_BUCKET_NAME, CopySource={"Bucket": B2_BUCKET_NAME, "Key": src_key}, Key=dst_key)
            s3.delete_object(Bucket=B2_BUCKET_NAME, Key=src_key)
        except ClientError as e:
            if e.response['Error']['Code'] != "NoSuchKey":
                logger.error(f"Error moving {src_key}: {e.response['Error']['Message']}")


def process_folders(s3, folders):
    """
    –û–±—Ö–æ–¥–∏—Ç —Å–ø–∏—Å–æ–∫ –ø–∞–ø–æ–∫, –ø—ã—Ç–∞–µ—Ç—Å—è –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å "–≥–æ—Ç–æ–≤—ã–µ" –≥—Ä—É–ø–ø—ã –∏–∑ –ø–∞–ø–æ–∫ —Å –±–æ–ª–µ–µ –Ω–∏–∑–∫–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
    –≤ –ø–∞–ø–∫–∏ —Å –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–º, –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏.
    –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ –æ–±–Ω–æ–≤–ª—è–µ—Ç –∫–ª—é—á "empty" –≤ config_public.json.
    """
    empty_folders = set()
    changes_made = True
    while changes_made:
        changes_made = False
        for i in range(len(folders) - 1, 0, -1):
            src_folder = folders[i]
            dst_folder = folders[i - 1]
            if src_folder in empty_folders:
                continue
            src_files = list_files_in_folder(s3, src_folder)
            dst_files = list_files_in_folder(s3, dst_folder)
            src_ready = get_ready_groups(src_files)
            dst_ready = get_ready_groups(dst_files)
            for group_id in src_ready:
                if len(dst_ready) < 1:
                    move_group(s3, src_folder, dst_folder, group_id)
                    changes_made = True
            if not src_ready:
                empty_folders.add(src_folder)
    # –í—ã–∑–æ–≤ is_folder_empty —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏: (s3, bucket_name, folder_prefix)
    if is_folder_empty(s3, B2_BUCKET_NAME, "666/"):
        logger.info("‚ö†Ô∏è –ü–∞–ø–∫–∞ 666/ –ø—É—Å—Ç–∞. –ó–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
        subprocess.run(["python", os.path.join(config.get('FILE_PATHS.scripts_folder'), "generate_content.py")], check=True)
    else:
        logger.info("‚úÖ –í—Å–µ –ø–∞–ø–∫–∏ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã. –ó–∞–≤–µ—Ä—à–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å.")
    config_data = load_config_public(s3)
    config_data["empty"] = list(empty_folders)
    save_config_public(s3, config_data)
    logger.info(f"üìÇ –û–±–Ω–æ–≤–ª–µ–Ω—ã –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏ –≤ config_public.json: {config_data['empty']}")


def run_generate_media():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Å–∫—Ä–∏–ø—Ç generate_media.py –ø–æ –ª–æ–∫–∞–ª—å–Ω–æ–º—É –ø—É—Ç–∏."""
    try:
        scripts_folder = config.get("FILE_PATHS.scripts_folder", "scripts")
        script_path = os.path.join(scripts_folder, "generate_media.py")
        if not os.path.isfile(script_path):
            raise FileNotFoundError(f"–°–∫—Ä–∏–ø—Ç generate_media.py –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏: {script_path}")
        logger.info(f"üîÑ –ó–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞: {script_path}")
        subprocess.run(["python", script_path], check=True)
        logger.info(f"‚úÖ –°–∫—Ä–∏–ø—Ç {script_path} –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ.")
    except subprocess.CalledProcessError as e:
        handle_error("Script Execution Error", f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ —Å–∫—Ä–∏–ø—Ç–∞ {script_path}: {e}")
    except FileNotFoundError as e:
        handle_error("File Not Found Error", str(e))
    except Exception as e:
        handle_error("Unknown Error", f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Å–∫—Ä–∏–ø—Ç–∞ {script_path}: {e}")


def main():
    """–û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è B2-—Ö—Ä–∞–Ω–∏–ª–∏—â–µ–º (–ø—É–±–ª–∏–∫–∞—Ç–æ—Ä)."""
    logger.info("üîÑ –ó–∞–ø—É—Å–∫ p—É–±–ª–∏–∫–∞—Ç–æ—Ä–∞ (b2_storage_manager.py) ...")
    try:
        # 1) –ó–∞–≥—Ä—É–∂–∞–µ–º config_public.json
        b2_client = get_b2_client()
        logger.info(f"üîç –°–∫–∞—á–∏–≤–∞–µ–º config_public.json –∏–∑ B2 ...")
        download_file_from_b2(b2_client, CONFIG_PUBLIC_REMOTE_PATH, CONFIG_PUBLIC_LOCAL_PATH)
        config_public = load_config_public(b2_client)

        # 2) –ï—Å–ª–∏ –µ—Å—Ç—å generation_id -> handle_publish() - –∞—Ä—Ö–∏–≤–∏—Ä—É–µ–º —Å—Ç–∞—Ä—ã–µ –≥—Ä—É–ø–ø—ã
        if "generation_id" in config_public and config_public["generation_id"]:
            logger.info(f"üìÇ –ù–∞–π–¥–µ–Ω—ã –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ –≥—Ä—É–ø–ø—ã: {config_public['generation_id']}. –ê—Ä—Ö–∏–≤–∏—Ä—É–µ–º ...")
            handle_publish(b2_client, config_public)
        else:
            logger.info("‚ö†Ô∏è –ù–µ—Ç –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö –≥—Ä—É–ø–ø (generation_id). –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–µ.")

        # 3) –°—Ä–∞–∑—É –ø–æ—Å–ª–µ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏—è: process_folders(...) - –ø–µ—Ä–µ–º–µ—â–∞–µ–º –≥–æ—Ç–æ–≤—ã–µ –≥—Ä—É–ø–ø—ã —Å–≤–µ—Ä—Ö—É –≤–Ω–∏–∑
        logger.info("üîÑ –í—ã–∑—ã–≤–∞–µ–º process_folders(...) –¥–ª—è –ø–µ—Ä–µ–∫–ª–∞–¥—ã–≤–∞–Ω–∏—è –≥—Ä—É–ø–ø (666‚Üí555‚Üí444).")
        process_folders(b2_client, FOLDERS)

        # 4) –ï—â—ë —Ä–∞–∑ –ø–µ—Ä–µ—á–∏—Ç—ã–≤–∞–µ–º config_public.json, —á—Ç–æ–±—ã —É–∑–Ω–∞—Ç—å, –Ω–µ —Å—Ç–∞–ª–∞ –ª–∏ –ø–∞–ø–∫–∞ –ø—É—Å—Ç–æ–π
        config_public = load_config_public(b2_client)
        empty_folders = config_public.get("empty", [])
        logger.info(f"üîé –ü—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏: {empty_folders}")

        # 5) –ï—Å–ª–∏ –≤—Å—ë –µ—â—ë –ø—É—Å—Ç–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 444/ –ø—É—Å—Ç–∞), –∑–∞–ø—É—Å–∫–∞–µ–º generate_content.py
        if empty_folders:
            logger.info(f"‚ö†Ô∏è –ï—Å—Ç—å –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏: {empty_folders}. –ó–∞–ø—É—Å–∫–∞–µ–º generate_content.py ...")
            subprocess.run(
                [
                    "python",
                    os.path.join(config.get('FILE_PATHS.scripts_folder'), "generate_content.py")
                ],
                check=True
            )
            logger.info("‚úÖ generate_content.py –∑–∞–≤–µ—Ä—à–∏–ª—Å—è. (–û–Ω —Å–∞–º –∑–∞–ø—É—Å—Ç–∏—Ç generate_media.py)")
        else:
            logger.info("‚úÖ –ü–∞–ø–∫–∏ –Ω–µ –ø—É—Å—Ç—ã–µ, –Ω–æ–≤—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ–º.")

        # 6) (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –ï—Å–ª–∏ –Ω—É–∂–Ω–æ, –º–æ–∂–Ω–æ –∑–¥–µ—Å—å –∑–∞–≤–µ—Ä—à–∏—Ç—å —Å–∫—Ä–∏–ø—Ç
        #    –∏ –≤–µ—Ä–Ω—É—Ç—å—Å—è –∫ –≤—ã–∑—ã–≤–∞—é—â–µ–º—É —Å–∫—Ä–∏–ø—Ç—É (generate_media.py –∏–ª–∏ CI/CD),
        #    –∫–æ—Ç–æ—Ä—ã–π –ø–æ –æ–∫–æ–Ω—á–∞–Ω–∏–∏ —Ç–æ–∂–µ –º–æ–∂–µ—Ç –≤—ã–∑–≤–∞—Ç—å —ç—Ç–æ—Ç b2_storage_manager.py –µ—â–µ —Ä–∞–∑.
        logger.info("‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ p—É–±–ª–∏–∫–∞—Ç–æ—Ä–∞ (b2_storage_manager.py).")

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ p—É–±–ª–∏–∫–∞—Ç–æ—Ä–µ: {e}")
        handle_error(logger, "–û—à–∏–±–∫–∞ –ø—É–±–ª–∏–∫–∞—Ç–æ—Ä–∞", e)


if __name__ == "__main__":
    main()
