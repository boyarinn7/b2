import os
import json
import logging
import subprocess
import re
import sys

from modules.utils import is_folder_empty, ensure_directory_exists
from scripts.generate_media import download_file_from_b2
from botocore.exceptions import ClientError
from modules.api_clients import get_b2_client
from modules.logger import get_logger
from modules.error_handler import handle_error
from modules.config_manager import ConfigManager

# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ===
config = ConfigManager()
logger = get_logger("b2_storage_manager")

# === –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ===
B2_BUCKET_NAME = config.get('API_KEYS.b2.bucket_name')
CONFIG_PUBLIC_PATH = config.get('FILE_PATHS.config_public')
CONFIG_PUBLIC_REMOTE_PATH = "config/config_public.json"
FILE_EXTENSIONS = ['.json', '.png', '.mp4']
FOLDERS = [
    config.get('FILE_PATHS.folder_444'),
    config.get('FILE_PATHS.folder_555'),
    config.get('FILE_PATHS.folder_666')
]
ARCHIVE_FOLDER = config.get('FILE_PATHS.archive_folder')
FILE_NAME_PATTERN = re.compile(r"^\d{8}-\d{4}\.\w+$")


def check_files_exist(s3, generation_id):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≥—Ä—É–ø–ø—ã –≤ —Ä–∞–±–æ—á–∏—Ö –ø–∞–ø–∫–∞—Ö."""
    for folder in FOLDERS:
        for ext in FILE_EXTENSIONS:
            key = f"{folder}{generation_id}{ext}"
            try:
                s3.head_object(Bucket=B2_BUCKET_NAME, Key=key)
                return True
            except ClientError:
                continue
    return False


def move_to_archive(s3, generation_id):
    """–ü–µ—Ä–µ–º–µ—â–∞–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã –≥—Ä—É–ø–ø—ã –≤ –∞—Ä—Ö–∏–≤."""
    success = True
    for folder in FOLDERS:
        for ext in FILE_EXTENSIONS:
            src_key = f"{folder}{generation_id}{ext}"
            dst_key = f"{ARCHIVE_FOLDER}{generation_id}{ext}"

            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ–º
                s3.head_object(Bucket=B2_BUCKET_NAME, Key=src_key)

                # –ö–æ–ø–∏—Ä—É–µ–º –≤ –∞—Ä—Ö–∏–≤
                s3.copy_object(
                    Bucket=B2_BUCKET_NAME,
                    CopySource={"Bucket": B2_BUCKET_NAME, "Key": src_key},
                    Key=dst_key
                )
                # –£–¥–∞–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
                s3.delete_object(Bucket=B2_BUCKET_NAME, Key=src_key)
                logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–º–µ—â–µ–Ω–æ: {src_key} -> {dst_key}")

            except ClientError as e:
                if e.response['Error']['Code'] != '404':
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏ {src_key}: {e}")
                    success = False
    return success


def handle_publish(s3, config_data):
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏ —Å –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏"""
    generation_ids = config_data.get("generation_id", [])

    if not generation_ids:
        logger.info("üìÇ –ù–µ—Ç generation_id –¥–ª—è –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏.")
        return

    if isinstance(generation_ids, str):
        generation_ids = [generation_ids]

    archived_ids = []

    for generation_id in generation_ids:
        logger.info(f"üîÑ –ê—Ä—Ö–∏–≤–∏—Ä—É–µ–º –≥—Ä—É–ø–ø—É: {generation_id}")

        if not check_files_exist(s3, generation_id):
            logger.error(f"‚ùå –§–∞–π–ª—ã –≥—Ä—É–ø–ø—ã {generation_id} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
            continue

        if move_to_archive(s3, generation_id):
            archived_ids.append(generation_id)
        else:
            logger.warning(f"‚ö†Ô∏è –ß–∞—Å—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞ –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏ {generation_id}")

    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–π –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏
    if archived_ids:
        config_data["generation_id"] = [gid for gid in generation_ids if gid not in archived_ids]
        if not config_data["generation_id"]:
            del config_data["generation_id"]

        try:
            with open(CONFIG_PUBLIC_PATH, 'w', encoding='utf-8') as f:
                json.dump(config_data, f, indent=4, ensure_ascii=False)
            s3.upload_file(CONFIG_PUBLIC_PATH, B2_BUCKET_NAME, CONFIG_PUBLIC_REMOTE_PATH)
            logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω—ã: {archived_ids}")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥–∞: {e}")
    else:
        logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–Ω—É –≥—Ä—É–ø–ø—É")


# –û—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
# ================================================
def load_config_public(s3):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç config_public.json –∏–∑ B2"""
    try:
        local_path = CONFIG_PUBLIC_PATH
        s3.download_file(B2_BUCKET_NAME, CONFIG_PUBLIC_REMOTE_PATH, local_path)
        with open(local_path, 'r', encoding='utf-8') as file:
            return json.load(file)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥–∞: {e}")
        return {}


def process_folders(s3, folders):
    """–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ –º–µ–∂–¥—É –ø–∞–ø–∫–∞–º–∏"""
    # ... (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)


def main():
    """–û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –æ—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    try:
        b2_client = get_b2_client()

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
        config_public = load_config_public(b2_client)
        if config_public.get("processing_lock"):
            logger.info("üîí –ü—Ä–æ—Ü–µ—Å—Å —É–∂–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è")
            return

        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
        config_public["processing_lock"] = True
        with open(CONFIG_PUBLIC_PATH, 'w', encoding='utf-8') as f:
            json.dump(config_public, f, indent=4)
        b2_client.upload_file(CONFIG_PUBLIC_PATH, B2_BUCKET_NAME, CONFIG_PUBLIC_REMOTE_PATH)

        # –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞
        config_public = load_config_public(b2_client)
        handle_publish(b2_client, config_public)
        process_folders(b2_client, FOLDERS)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—É—Å—Ç—ã—Ö –ø–∞–ø–æ–∫
        config_public = load_config_public(b2_client)
        if config_public.get("empty"):
            logger.info("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏, –∑–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é...")
            subprocess.run(["python", "scripts/generate_content.py"], check=True)

    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
    finally:
        # –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–Ω—è—Ç–∏–µ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
        try:
            config_public = load_config_public(b2_client)
            config_public["processing_lock"] = False
            with open(CONFIG_PUBLIC_PATH, 'w', encoding='utf-8') as f:
                json.dump(config_public, f, indent=4)
            b2_client.upload_file(CONFIG_PUBLIC_PATH, B2_BUCKET_NAME, CONFIG_PUBLIC_REMOTE_PATH)
            logger.info("üîì –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ —Å–Ω—è—Ç–∞")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–Ω—è—Ç–∏—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏: {e}")


if __name__ == "__main__":
    main()