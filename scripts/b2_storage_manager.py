import os
import json
import logging
import subprocess
import re
import sys
from botocore.exceptions import ClientError

script_dir = os.path.dirname(__file__)
parent_dir = os.path.abspath(os.path.join(script_dir, '..'))
sys.path.append(parent_dir)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("b2_storage_manager")
logger.info(f"Script directory: {script_dir}")
logger.info(f"Parent directory added to sys.path: {parent_dir}")
logger.info(f"Full sys.path: {sys.path}")
logger.info(f"Does modules/ exist? {os.path.isdir(os.path.join(parent_dir, 'modules'))}")
logger.info(f"Does modules/utils.py exist? {os.path.isfile(os.path.join(parent_dir, 'modules', 'utils.py'))}")

from modules.utils import is_folder_empty, ensure_directory_exists
from scripts.generate_media import download_file_from_b2
from modules.api_clients import get_b2_client
from modules.logger import get_logger
from modules.error_handler import handle_error
from modules.config_manager import ConfigManager

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è (–æ—Å—Ç–∞–≤–ª—è–µ–º ConfigManager –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π –æ—Ç–ª–∞–¥–∫–∏, –Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º os.getenv –¥–ª—è Actions)
config = ConfigManager()
logger = get_logger("b2_storage_manager")
logger.info("–ù–∞—á–∞–ª–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è b2_storage_manager")
logger.info(f"–¢–µ–∫—É—â–∞—è —Ä–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {os.getcwd()}")

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
CONFIG_PUBLIC_PATH = os.getenv("CONFIG_PUBLIC_PATH", "config_public.json")
logger.info(f"–õ–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å CONFIG_PUBLIC_PATH: {CONFIG_PUBLIC_PATH}")
CONFIG_PUBLIC_REMOTE_PATH = "config/config_public.json"
FILE_EXTENSIONS = ['.json', '.png', '.mp4']
FOLDERS = [
    config.get("FILE_PATHS.folder_444", "444/"),
    config.get("FILE_PATHS.folder_555", "555/"),
    config.get("FILE_PATHS.folder_666", "666/")
]
ARCHIVE_FOLDER = config.get("FILE_PATHS.archive_folder", "archive/")
GENERATE_CONTENT_SCRIPT = os.path.join(config.get("FILE_PATHS.scripts_folder", "scripts"), "generate_content.py")
FILE_NAME_PATTERN = re.compile(r"^\d{8}-\d{4}\.\w+$")
logger.info(f"–ü—É—Ç—å –∫ generate_content.py: {GENERATE_CONTENT_SCRIPT}")

# –î–æ–±–∞–≤–∏–º –æ—Ç–ª–∞–¥–∫—É –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–Ω–∞—á–µ–Ω–∏–π
logger.info(f"FOLDERS: {FOLDERS}")
logger.info(f"ARCHIVE_FOLDER: {ARCHIVE_FOLDER}")

def load_config_public(s3):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç config_public.json –∏–∑ B2."""
    try:
        local_path = CONFIG_PUBLIC_PATH
        bucket_name = os.getenv("B2_BUCKET_NAME")
        if not bucket_name:
            raise ValueError("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è B2_BUCKET_NAME –Ω–µ –∑–∞–¥–∞–Ω–∞")
        os.makedirs(os.path.dirname(local_path), exist_ok=True)
        logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ B2: {CONFIG_PUBLIC_REMOTE_PATH} –≤ {local_path}")
        s3.download_file(bucket_name, CONFIG_PUBLIC_REMOTE_PATH, local_path)
        with open(local_path, 'r', encoding='utf-8') as file:
            data = json.load(file)
        logger.info(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {local_path}: {json.dumps(data, ensure_ascii=False)}")
        return data
    except ClientError as e:
        if e.response['Error']['Code'] == '404':
            logger.warning("‚ö†Ô∏è –ö–æ–Ω—Ñ–∏–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π.")
            new_data = {"processing_lock": False, "empty": [], "generation_id": []}
            logger.info(f"–°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π –∫–æ–Ω—Ñ–∏–≥: {json.dumps(new_data, ensure_ascii=False)}")
            return new_data
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥–∞: {e}")
        return {}
    except Exception as e:
        logger.error(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∫–æ–Ω—Ñ–∏–≥–∞: {e}")
        return {}

def save_config_public(s3, data):
    try:
        bucket_name = os.getenv("B2_BUCKET_NAME")
        if not bucket_name:
            raise ValueError("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è B2_BUCKET_NAME –Ω–µ –∑–∞–¥–∞–Ω–∞")
        with open(CONFIG_PUBLIC_PATH, 'w', encoding='utf-8') as file:
            json.dump(data, file, ensure_ascii=False, indent=4)
        s3.upload_file(CONFIG_PUBLIC_PATH, bucket_name, CONFIG_PUBLIC_REMOTE_PATH)
        logger.info(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞. –ù–æ–≤–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ: {json.dumps(data, ensure_ascii=False)}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥–∞: {e}")

def list_files_in_folder(s3, folder_prefix):
    bucket_name = os.getenv("B2_BUCKET_NAME")
    if not bucket_name:
        raise ValueError("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è B2_BUCKET_NAME –Ω–µ –∑–∞–¥–∞–Ω–∞")
    try:
        response = s3.list_objects_v2(Bucket=bucket_name, Prefix=folder_prefix)
        return [
            obj['Key'] for obj in response.get('Contents', [])
            if obj['Key'] != folder_prefix and not obj['Key'].endswith('.bzEmpty')
               and FILE_NAME_PATTERN.match(os.path.basename(obj['Key']))
        ]
    except ClientError as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤: {e}")
        return []

def get_ready_groups(files):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –≥—Ä—É–ø–ø, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∞–π–ª—ã —Å–æ –≤—Å–µ–º–∏ —Ç—Ä–µ–±—É–µ–º—ã–º–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏.
    –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –≥—Ä—É–ø–ø—ã –ø–æ–ª—É—á–∞–µ—Ç—Å—è –∫–∞–∫ –∏–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è.
    """
    groups = {}
    for file_key in files:
        base_name = os.path.basename(file_key)
        if FILE_NAME_PATTERN.match(base_name):
            group_id = base_name.rsplit('.', 1)[0]
            groups.setdefault(group_id, []).append(base_name)
    return [
        group_id for group_id, file_list in groups.items()
        if all(f"{group_id}{ext}" in file_list for ext in FILE_EXTENSIONS)
    ]

def move_group(s3, src_folder, dst_folder, group_id):
    bucket_name = os.getenv("B2_BUCKET_NAME")
    if not bucket_name:
        raise ValueError("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è B2_BUCKET_NAME –Ω–µ –∑–∞–¥–∞–Ω–∞")
    for ext in FILE_EXTENSIONS:
        src_key = f"{src_folder}{group_id}{ext}"
        dst_key = f"{dst_folder}{group_id}{ext}"
        try:
            s3.head_object(Bucket=bucket_name, Key=src_key)
            s3.copy_object(
                Bucket=bucket_name,
                CopySource={"Bucket": bucket_name, "Key": src_key},
                Key=dst_key
            )
            s3.delete_object(Bucket=bucket_name, Key=src_key)
            logger.info(f"‚úÖ –ü–µ—Ä–µ–º–µ—â–µ–Ω–æ: {src_key} -> {dst_key}")
        except ClientError as e:
            if e.response['Error']['Code'] != "NoSuchKey":
                logger.error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è {src_key}: {e}")

def process_folders(s3, folders):
    bucket_name = os.getenv("B2_BUCKET_NAME")
    if not bucket_name:
        raise ValueError("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è B2_BUCKET_NAME –Ω–µ –∑–∞–¥–∞–Ω–∞")
    logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–π bucket_name: {bucket_name}")
    empty_folders = set()
    changes_made = True

    while changes_made:
        changes_made = False
        for i in range(len(folders) - 1, 0, -1):
            src_folder = folders[i]
            dst_folder = folders[i - 1]

            if src_folder in empty_folders:
                continue

            src_files = list_files_in_folder(s3, src_folder)
            dst_files = list_files_in_folder(s3, dst_folder)

            src_ready = get_ready_groups(src_files)
            dst_ready = get_ready_groups(dst_files)

            for group_id in src_ready:
                if len(dst_ready) < 1:
                    move_group(s3, src_folder, dst_folder, group_id)
                    changes_made = True

            if not src_ready:
                empty_folders.add(src_folder)

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–∫—É —á–µ—Ä–µ–∑ any_folder_empty (–ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –ø–æ–ª–Ω—ã—Ö –≥—Ä—É–ø–ø)
    # if is_folder_empty(s3, bucket_name, folders[-1]):
    #     logger.info("‚ö†Ô∏è –ü–∞–ø–∫–∞ 666/ –ø—É—Å—Ç–∞. –ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
    #     if not os.path.exists(GENERATE_CONTENT_SCRIPT):
    #         logger.error(f"–û—à–∏–±–∫–∞: generate_content.py –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏ {GENERATE_CONTENT_SCRIPT}")
    #         return
    #     subprocess.run([sys.executable, GENERATE_CONTENT_SCRIPT], check=True)
    #     sys.exit(0)  # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ—Å–ª–µ –≤—ã–∑–æ–≤–∞ generate_content.py

    config_data = load_config_public(s3)
    config_data["empty"] = list(empty_folders)
    save_config_public(s3, config_data)
    logger.info(f"üìÇ –û–±–Ω–æ–≤–ª–µ–Ω—ã –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏: {config_data.get('empty')}")

def handle_publish(s3, config_data):
    bucket_name = os.getenv("B2_BUCKET_NAME")
    if not bucket_name:
        raise ValueError("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è B2_BUCKET_NAME –Ω–µ –∑–∞–¥–∞–Ω–∞")
    generation_ids = config_data.get("generation_id", [])

    if not generation_ids:
        logger.info("üìÇ –ù–µ—Ç generation_id –¥–ª—è –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏.")
        return

    if isinstance(generation_ids, str):
        generation_ids = [generation_ids]

    archived_ids = []

    for generation_id in generation_ids:
        logger.info(f"üîÑ –ê—Ä—Ö–∏–≤–∏—Ä—É–µ–º –≥—Ä—É–ø–ø—É: {generation_id}")

        files_exist = any(list_files_in_folder(s3, folder) for folder in FOLDERS)
        if not files_exist:
            logger.error(f"‚ùå –§–∞–π–ª—ã –≥—Ä—É–ø–ø—ã {generation_id} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
            continue

        success = True
        for folder in FOLDERS:
            for ext in FILE_EXTENSIONS:
                src_key = f"{folder}{generation_id}{ext}"
                dst_key = f"{ARCHIVE_FOLDER}{generation_id}{ext}"
                try:
                    s3.head_object(Bucket=bucket_name, Key=src_key)
                    s3.copy_object(
                        Bucket=bucket_name,
                        CopySource={"Bucket": bucket_name, "Key": src_key},
                        Key=dst_key
                    )
                    s3.delete_object(Bucket=bucket_name, Key=src_key)
                    logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–º–µ—â–µ–Ω–æ: {src_key} -> {dst_key}")
                except ClientError as e:
                    if e.response['Error']['Code'] != '404':
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏ {src_key}: {e}")
                        success = False
        if success:
            archived_ids.append(generation_id)

    if archived_ids:
        config_data["generation_id"] = [gid for gid in generation_ids if gid not in archived_ids]
        if not config_data["generation_id"]:
            del config_data["generation_id"]
        save_config_public(s3, config_data)
        logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω—ã: {archived_ids}")
    else:
        logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–Ω—É –≥—Ä—É–ø–ø—É.")

def check_midjourney_results(b2_client):
    bucket_name = os.getenv("B2_BUCKET_NAME")
    if not bucket_name:
        raise ValueError("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è B2_BUCKET_NAME –Ω–µ –∑–∞–¥–∞–Ω–∞")
    remote_config = "config/config_public.json"
    try:
        config_obj = b2_client.get_object(Bucket=bucket_name, Key=remote_config)
        config_data = json.loads(config_obj['Body'].read().decode('utf-8'))
        midjourney_results = config_data.get("midjourney_results", None)
        if midjourney_results and not isinstance(midjourney_results, dict):
            logger.warning("‚ö†Ô∏è midjourney_results –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º, –æ—á–∏—â–∞–µ–º –∫–ª—é—á")
            config_data["midjourney_results"] = None
            save_config_public(b2_client, config_data)
        return midjourney_results
    except json.JSONDecodeError as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞–∑–±–æ—Ä–∞ JSON –≤ config_public.json: {e}")
        return None
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ midjourney_results: {e}")
        return None

def any_folder_empty(s3, folders):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ —Å—Ä–µ–¥–∏ –∑–∞–¥–∞–Ω–Ω—ã—Ö –ø–∞–ø–æ–∫ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–∞, –≤ –∫–æ—Ç–æ—Ä–æ–π –Ω–µ—Ç –ø–æ–ª–Ω—ã—Ö –≥—Ä—É–ø–ø —Ñ–∞–π–ª–æ–≤.
    –ü–æ–ª–Ω–∞—è –≥—Ä—É–ø–ø–∞ ‚Äî —ç—Ç–æ –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–º –∏ —Ç—Ä–µ–±—É–µ–º—ã–º–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏ (.json, .png, .mp4).
    """
    for folder in folders:
        logger.info(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–ø–∫—É: {folder}")
        files = list_files_in_folder(s3, folder)
        logger.info(f"–ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ {folder}: {files}")
        ready_groups = get_ready_groups(files)
        logger.info(f"–ü–æ–ª–Ω—ã–µ –≥—Ä—É–ø–ø—ã –≤ –ø–∞–ø–∫–µ {folder}: {ready_groups}")
        if not ready_groups:
            logger.info(f"–ü–∞–ø–∫–∞ {folder} —Å—á–∏—Ç–∞–µ—Ç—Å—è –ø—É—Å—Ç–æ–π (–Ω–µ—Ç –ø–æ–ª–Ω—ã—Ö –≥—Ä—É–ø–ø).")
            return True
        else:
            logger.info(f"–ü–∞–ø–∫–∞ {folder} —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–ª–Ω—ã–µ –≥—Ä—É–ø–ø—ã.")
    return False


def main():
    b2_client = None
    generation_count = 0
    MAX_GENERATIONS = 3
    SCRIPTS_FOLDER = os.path.abspath(config.get("FILE_PATHS.scripts_folder", "scripts"))

    try:
        b2_client = get_b2_client()
        logger.info("–ö–ª–∏–µ–Ω—Ç B2 —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω.")
        config_public = load_config_public(b2_client)

        # –®–∞–≥ 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–∞ midjourney_results
        midjourney_results = config_public.get("midjourney_results")
        if midjourney_results:
            image_urls = midjourney_results.get("image_urls", [])
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏: –≤—Å–µ URL –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å—Ç—Ä–æ–∫–∞–º–∏, –Ω–∞—á–∏–Ω–∞—é—â–∏–º–∏—Å—è —Å http/https
            if image_urls and all(isinstance(url, str) and url.startswith("http") for url in image_urls):
                logger.info("–ù–∞–π–¥–µ–Ω –≤–∞–ª–∏–¥–Ω—ã–π midjourney_results, –∑–∞–ø—É—Å–∫–∞–µ–º generate_media.py")
                generate_media_path = os.path.join(SCRIPTS_FOLDER, "generate_media.py")
                if not os.path.isfile(generate_media_path):
                    raise FileNotFoundError(f"‚ùå –§–∞–π–ª {generate_media_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
                # –°–Ω–∏–º–∞–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫—É –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –º–µ–¥–∏–∞, –µ—Å–ª–∏ –æ–Ω–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞
                if config_public.get("processing_lock"):
                    config_public["processing_lock"] = False
                    save_config_public(b2_client, config_public)
                    logger.info("üîì –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ —Å–Ω—è—Ç–∞ –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º generate_media.py")
                subprocess.run([sys.executable, generate_media_path], check=True)
                sys.exit(0)
            else:
                logger.warning("‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ midjourney_results, –æ—á–∏—â–∞–µ–º –∫–ª—é—á")
                if "midjourney_results" in config_public:
                    del config_public["midjourney_results"]
                    save_config_public(b2_client, config_public)

        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø–æ—Å–ª–µ –≤–æ–∑–º–æ–∂–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏ midjourney_results
        config_public = load_config_public(b2_client)

        # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ–∂–Ω—é—é –ø—Ä–æ–≤–µ—Ä–∫—É, —á—Ç–æ–±—ã –Ω–µ –∑–∞–≤–µ—Ä—à–∞—Ç—å —Ä–∞–±–æ—Ç—É —Ä–∞–Ω—å—à–µ –≤—Ä–µ–º–µ–Ω–∏:
        # if not config_public.get("generation_id") and not config_public.get("empty"):
        #     logger.info("üö¶ –ù–µ—Ç –∑–∞–ø–∏—Å–µ–π –æ –ø—É–±–ª–∏–∫–∞—Ü–∏—è—Ö –∏ –ø—É—Å—Ç—ã—Ö –ø–∞–ø–æ–∫. –°–∫—Ä–∏–ø—Ç –∑–∞–≤–µ—Ä—à–∞–µ—Ç —Ä–∞–±–æ—Ç—É.")
        #     return

        # –ï—Å–ª–∏ –ø—Ä–æ—Ü–µ—Å—Å —É–∂–µ –∑–∞–ø—É—â–µ–Ω (–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞), –∑–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É.
        if config_public.get("processing_lock"):
            logger.info("üîí –ü—Ä–æ—Ü–µ—Å—Å —É–∂–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è. –ó–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É.")
            return

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫—É
        config_public["processing_lock"] = True
        save_config_public(b2_client, config_public)
        logger.info("üîí –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")

        # –ê—Ä—Ö–∏–≤–∞—Ü–∏—è –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö –≥—Ä—É–ø–ø (–µ—Å–ª–∏ –∏–º–µ—é—Ç—Å—è)
        config_public = load_config_public(b2_client)
        if config_public.get("generation_id"):
            handle_publish(b2_client, config_public)

        # –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –≥—Ä—É–ø–ø –º–µ–∂–¥—É –ø–∞–ø–∫–∞–º–∏ (–æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –æ—á–µ—Ä–µ–¥–Ω–æ—Å—Ç—å –ø—É–±–ª–∏–∫–∞—Ü–∏–π)
        process_folders(b2_client, FOLDERS)
        config_public = load_config_public(b2_client)
        logger.info(f"–ü–æ—Å–ª–µ process_folders() config_public: {config_public}")

        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è –ø–∞–ø–æ–∫
        config_public = load_config_public(b2_client)
        logger.info(f"–ü–æ—Å–ª–µ process_folders() config_public: {config_public}")

        # –¶–∏–∫–ª –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: –µ—Å–ª–∏ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –æ—Å—Ç–∞—é—Ç—Å—è –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏ (–Ω–µ—Ç –ø–æ–ª–Ω—ã—Ö –≥—Ä—É–ø–ø), –∑–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        config_public = load_config_public(b2_client)
        while config_public.get("empty") and generation_count < MAX_GENERATIONS:
            logger.info(
                f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏ ({config_public['empty']}), –≥–µ–Ω–µ—Ä–∞—Ü–∏—è #{generation_count + 1} –∏–∑ {MAX_GENERATIONS}...")
            subprocess.run([sys.executable, GENERATE_CONTENT_SCRIPT], check=True)
            sys.exit(0)  # –ó–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –≤—ã–∑–æ–≤–∞ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            generation_count += 1  # –≠—Ç–∞ —Å—Ç—Ä–æ–∫–∞, –≤–µ—Ä–æ—è—Ç–Ω–æ, –Ω–µ –≤—ã–ø–æ–ª–Ω–∏—Ç—Å—è –∏–∑-–∑–∞ sys.exit(0)
            config_public = load_config_public(b2_client)
            logger.info(f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è #{generation_count}. –ü—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏: {config_public.get('empty', [])}")

        if generation_count >= MAX_GENERATIONS:
            logger.info(
                f"üö´ –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–π ({MAX_GENERATIONS}). –ó–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É, –¥–∞–∂–µ –µ—Å–ª–∏ –æ—Å—Ç–∞–ª–∏—Å—å –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏: {config_public.get('empty', [])}")
        elif not config_public.get("empty"):
            logger.info("‚úÖ –ù–µ—Ç –ø—É—Å—Ç—ã—Ö –ø–∞–ø–æ–∫ ‚Äì –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")

    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
    finally:
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫—É –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if b2_client:
            try:
                config_public = load_config_public(b2_client)
                if config_public.get("processing_lock"):
                    config_public["processing_lock"] = False
                    save_config_public(b2_client, config_public)
                    logger.info("üîì –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ —Å–Ω—è—Ç–∞.")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —Ä–∞–±–æ—Ç—ã: {e}")
        sys.exit(0)

if __name__ == "__main__":
    main()
