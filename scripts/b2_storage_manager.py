import os
import json
import logging
import subprocess
import re
import sys

from modules.utils import is_folder_empty, ensure_directory_exists
from modules.api_clients import get_b2_client
from modules.logger import get_logger
from modules.error_handler import handle_error
from modules.config_manager import ConfigManager

# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ===
config = ConfigManager()
logger = get_logger("b2_storage_manager")

# === –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ===
B2_BUCKET_NAME = config.get('API_KEYS.b2.bucket_name', 'boyarinnbotbucket')
CONFIG_PUBLIC_LOCAL_PATH = "config/config_public.json"  # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å
CONFIG_PUBLIC_REMOTE_PATH = "config/config_public.json"  # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –≤ B2
FILE_EXTENSIONS = ['.json', '.png', '.mp4']
FOLDERS = [
    config.get('FILE_PATHS.folder_444', '444/'),
    config.get('FILE_PATHS.folder_555', '555/'),
    config.get('FILE_PATHS.folder_666', '666/')
]
ARCHIVE_FOLDER = config.get('FILE_PATHS.archive_folder', 'data/archive/')
FILE_NAME_PATTERN = re.compile(r"^\d{8}-\d{4}\.\w+$")

# –ü—É—Ç—å –∫ —Å–∫—Ä–∏–ø—Ç—É –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
GENERATE_CONTENT_SCRIPT = os.path.join(config.get('FILE_PATHS.scripts_folder', 'scripts'), "generate_content.py")
SCRIPTS_FOLDER = config.get('FILE_PATHS.scripts_folder', 'scripts')

def download_file_from_b2(client, remote_path, local_path):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª –∏–∑ B2 –≤ –ª–æ–∫–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ."""
    try:
        logger.info(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –∏–∑ B2: {remote_path} -> {local_path}")
        ensure_directory_exists(os.path.dirname(local_path))
        client.download_file(B2_BUCKET_NAME, remote_path, local_path)
        logger.info(f"‚úÖ –§–∞–π–ª '{remote_path}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ {local_path}")
    except Exception as e:
        handle_error("B2 Download Error", str(e), e)

def load_config_public(s3):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç config_public.json –∏–∑ B2."""
    try:
        local_path = CONFIG_PUBLIC_LOCAL_PATH
        download_file_from_b2(s3, CONFIG_PUBLIC_REMOTE_PATH, local_path)
        with open(local_path, 'r', encoding='utf-8') as file:
            data = json.load(file)
        logger.info("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
        return data
    except Exception as e:
        logger.warning("‚ö†Ô∏è –ö–æ–Ω—Ñ–∏–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π.")
        return {"processing_lock": False, "empty": [], "generation_id": []}

def save_config_public(s3, data):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç config_public.json –≤ B2."""
    try:
        os.makedirs(os.path.dirname(CONFIG_PUBLIC_LOCAL_PATH), exist_ok=True)
        with open(CONFIG_PUBLIC_LOCAL_PATH, 'w', encoding='utf-8') as file:
            json.dump(data, file, ensure_ascii=False, indent=4)
        s3.upload_file(CONFIG_PUBLIC_LOCAL_PATH, B2_BUCKET_NAME, CONFIG_PUBLIC_REMOTE_PATH)
        logger.info("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.")
        os.remove(CONFIG_PUBLIC_LOCAL_PATH)
        logger.info(f"üóëÔ∏è –õ–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª {CONFIG_PUBLIC_LOCAL_PATH} —É–¥–∞–ª—ë–Ω.")
    except Exception as e:
        handle_error("Save Config Public Error", str(e), e)

def list_files_in_folder(s3, folder_prefix):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–µ (–∫—Ä–æ–º–µ placeholder)."""
    try:
        response = s3.list_objects_v2(Bucket=B2_BUCKET_NAME, Prefix=folder_prefix)
        return [
            obj['Key'] for obj in response.get('Contents', [])
            if obj['Key'] != folder_prefix and not obj['Key'].endswith('.bzEmpty')
               and FILE_NAME_PATTERN.match(os.path.basename(obj['Key']))
        ]
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤: {e}")
        return []

def get_ready_groups(files):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –≥—Ä—É–ø–ø —Å —Ñ–∞–π–ª–∞–º–∏ –≤—Å–µ—Ö —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π."""
    groups = {}
    for file_key in files:
        base_name = os.path.basename(file_key)
        if FILE_NAME_PATTERN.match(base_name):
            group_id = base_name.rsplit('.', 1)[0]
            groups.setdefault(group_id, []).append(base_name)
    return [
        group_id for group_id, file_list in groups.items()
        if all(f"{group_id}{ext}" in file_list for ext in FILE_EXTENSIONS)
    ]

def move_group(s3, src_folder, dst_folder, group_id):
    """–ü–µ—Ä–µ–º–µ—â–∞–µ—Ç —Ñ–∞–π–ª—ã –≥—Ä—É–ø–ø—ã –∏–∑ src_folder –≤ dst_folder."""
    for ext in FILE_EXTENSIONS:
        src_key = f"{src_folder}{group_id}{ext}"
        dst_key = f"{dst_folder}{group_id}{ext}"
        try:
            s3.head_object(Bucket=B2_BUCKET_NAME, Key=src_key)
            s3.copy_object(
                Bucket=B2_BUCKET_NAME,
                CopySource={"Bucket": B2_BUCKET_NAME, "Key": src_key},
                Key=dst_key
            )
            s3.delete_object(Bucket=B2_BUCKET_NAME, Key=src_key)
            logger.info(f"‚úÖ –ü–µ—Ä–µ–º–µ—â–µ–Ω–æ: {src_key} -> {dst_key}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è {src_key}: {e}")

def process_folders(s3, folders):
    """–ü–µ—Ä–µ–º–µ—â–∞–µ—Ç –≥—Ä—É–ø–ø—ã —Ñ–∞–π–ª–æ–≤ –º–µ–∂–¥—É –ø–∞–ø–∫–∞–º–∏ –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏."""
    empty_folders = set()
    changes_made = True

    while changes_made:
        changes_made = False
        for i in range(len(folders) - 1, 0, -1):
            src_folder = folders[i]
            dst_folder = folders[i - 1]

            if src_folder in empty_folders:
                continue

            src_files = list_files_in_folder(s3, src_folder)
            dst_files = list_files_in_folder(s3, dst_folder)

            src_ready = get_ready_groups(src_files)
            dst_ready = get_ready_groups(dst_files)

            for group_id in src_ready:
                if len(dst_ready) < 1:
                    move_group(s3, src_folder, dst_folder, group_id)
                    changes_made = True

            if not src_ready:
                empty_folders.add(src_folder)

    if is_folder_empty(s3, B2_BUCKET_NAME, folders[-1]):
        logger.info("‚ö†Ô∏è –ü–∞–ø–∫–∞ 666/ –ø—É—Å—Ç–∞. –ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
        subprocess.run([sys.executable, GENERATE_CONTENT_SCRIPT], check=True)

    config_data = load_config_public(s3)
    config_data["empty"] = list(empty_folders)
    save_config_public(s3, config_data)
    logger.info(f"üìÇ –û–±–Ω–æ–≤–ª–µ–Ω—ã –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏: {config_data.get('empty')}")

def handle_publish(s3, config_data):
    """–ê—Ä—Ö–∏–≤–∏—Ä—É–µ—Ç –≥—Ä—É–ø–ø—ã —Ñ–∞–π–ª–æ–≤ –ø–æ generation_id."""
    generation_ids = config_data.get("generation_id", [])

    if not generation_ids:
        logger.info("üìÇ –ù–µ—Ç generation_id –¥–ª—è –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏.")
        return

    if isinstance(generation_ids, str):
        generation_ids = [generation_ids]

    archived_ids = []

    for generation_id in generation_ids:
        logger.info(f"üîÑ –ê—Ä—Ö–∏–≤–∏—Ä—É–µ–º –≥—Ä—É–ø–ø—É: {generation_id}")

        files_exist = any(list_files_in_folder(s3, folder) for folder in FOLDERS)
        if not files_exist:
            logger.error(f"‚ùå –§–∞–π–ª—ã –≥—Ä—É–ø–ø—ã {generation_id} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
            continue

        success = True
        for folder in FOLDERS:
            for ext in FILE_EXTENSIONS:
                src_key = f"{folder}{generation_id}{ext}"
                dst_key = f"{ARCHIVE_FOLDER}{generation_id}{ext}"
                try:
                    s3.head_object(Bucket=B2_BUCKET_NAME, Key=src_key)
                    s3.copy_object(
                        Bucket=B2_BUCKET_NAME,
                        CopySource={"Bucket": B2_BUCKET_NAME, "Key": src_key},
                        Key=dst_key
                    )
                    s3.delete_object(Bucket=B2_BUCKET_NAME, Key=src_key)
                    logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–º–µ—â–µ–Ω–æ: {src_key} -> {dst_key}")
                except Exception as e:
                    if '404' not in str(e):
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏ {src_key}: {e}")
                        success = False
        if success:
            archived_ids.append(generation_id)

    if archived_ids:
        config_data["generation_id"] = [gid for gid in generation_ids if gid not in archived_ids]
        if not config_data["generation_id"]:
            del config_data["generation_id"]
        save_config_public(s3, config_data)
        logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω—ã: {archived_ids}")
    else:
        logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–Ω—É –≥—Ä—É–ø–ø—É.")

def check_midjourney_results(b2_client):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ midjourney_results –≤ config_public.json."""
    try:
        download_file_from_b2(b2_client, CONFIG_PUBLIC_REMOTE_PATH, CONFIG_PUBLIC_LOCAL_PATH)
        with open(CONFIG_PUBLIC_LOCAL_PATH, 'r', encoding='utf-8') as file:
            config_data = json.load(file)
        os.remove(CONFIG_PUBLIC_LOCAL_PATH)
        return config_data.get("midjourney_results", None)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ midjourney_results: {e}")
        return None

def main():
    """–û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è B2-—Ö—Ä–∞–Ω–∏–ª–∏—â–µ–º."""
    b2_client = None
    generation_count = 0
    MAX_GENERATIONS = 1

    try:
        b2_client = get_b2_client()
        if not b2_client:
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∫–ª–∏–µ–Ω—Ç B2")

        midjourney_results = check_midjourney_results(b2_client)
        if midjourney_results:
            logger.info("–ù–∞–π–¥–µ–Ω midjourney_results, –∑–∞–ø—É—Å–∫–∞–µ–º generate_media.py")
            subprocess.run([sys.executable, os.path.join(SCRIPTS_FOLDER, "generate_media.py")], check=True)
            return

        config_public = load_config_public(b2_client)

        if not config_public.get("generation_id") and not config_public.get("empty"):
            logger.info("üö¶ –ù–µ—Ç –∑–∞–ø–∏—Å–µ–π –æ –ø—É–±–ª–∏–∫–∞—Ü–∏—è—Ö –∏ –ø—É—Å—Ç—ã—Ö –ø–∞–ø–æ–∫. –°–∫—Ä–∏–ø—Ç –∑–∞–≤–µ—Ä—à–∞–µ—Ç —Ä–∞–±–æ—Ç—É.")
            return

        if config_public.get("processing_lock"):
            logger.info("üîí –ü—Ä–æ—Ü–µ—Å—Å —É–∂–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è. –ó–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É.")
            return

        config_public["processing_lock"] = True
        save_config_public(b2_client, config_public)
        logger.info("üîí –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")

        config_public = load_config_public(b2_client)
        if config_public.get("generation_id"):
            handle_publish(b2_client, config_public)

        process_folders(b2_client, FOLDERS)

        config_public = load_config_public(b2_client)
        while config_public.get("empty") and generation_count < MAX_GENERATIONS:
            logger.info(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏ ({config_public['empty']}), –≥–µ–Ω–µ—Ä–∞—Ü–∏—è #{generation_count + 1} –∏–∑ {MAX_GENERATIONS}...")
            subprocess.run([sys.executable, GENERATE_CONTENT_SCRIPT], check=True)
            generation_count += 1
            config_public = load_config_public(b2_client)
            logger.info(f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è #{generation_count}. –ü—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏: {config_public.get('empty', [])}")

        if generation_count >= MAX_GENERATIONS:
            logger.info(f"üö´ –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–π ({MAX_GENERATIONS}). –ó–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É, –¥–∞–∂–µ –µ—Å–ª–∏ –æ—Å—Ç–∞–ª–∏—Å—å –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏: {config_public.get('empty', [])}")
        elif not config_public.get("empty"):
            logger.info("‚úÖ –ù–µ—Ç –ø—É—Å—Ç—ã—Ö –ø–∞–ø–æ–∫ ‚Äì –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")

    except Exception as e:
        handle_error("Main Error", str(e), e)
    finally:
        if b2_client:
            try:
                config_public = load_config_public(b2_client)
                if config_public.get("processing_lock"):
                    config_public["processing_lock"] = False
                    save_config_public(b2_client, config_public)
                    logger.info("üîì –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ —Å–Ω—è—Ç–∞.")
            except Exception as e:
                handle_error("Unlock Error", str(e), e)

if __name__ == "__main__":
    main()