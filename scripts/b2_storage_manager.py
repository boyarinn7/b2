import os
import json
import logging
import subprocess  # –î–ª—è –∑–∞–ø—É—Å–∫–∞ –≤–Ω–µ—à–Ω–∏—Ö —Å–∫—Ä–∏–ø—Ç–æ–≤
import re

from modules.utils import is_folder_empty, ensure_directory_exists, move_to_archive
from scripts.generate_media import download_file_from_b2, generate_mock_video, update_config_public, upload_to_b2
from botocore.exceptions import ClientError
from modules.api_clients import get_b2_client
from modules.logger import get_logger
from modules.error_handler import handle_error
from modules.config_manager import ConfigManager

# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ===
config = ConfigManager()
logger = get_logger("b2_storage_manager")

# === –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ===
B2_BUCKET_NAME = config.get('API_KEYS.b2.bucket_name')
CONFIG_PUBLIC_PATH = config.get('FILE_PATHS.config_public')  # –Ω–∞–ø—Ä–∏–º–µ—Ä, "config/config_public.json"
CONFIG_GEN_PATH = os.path.abspath('config/config_gen.json')
CONFIG_PUBLIC_REMOTE_PATH = "config/config_public.json"  # –∫–ª—é—á –≤ B2
CONFIG_PUBLIC_LOCAL_PATH = os.path.abspath('config_public.json')
FILE_EXTENSIONS = ['.json', '.png', '.mp4']
FOLDERS = [
    config.get('FILE_PATHS.folder_444'),
    config.get('FILE_PATHS.folder_555'),
    config.get('FILE_PATHS.folder_666')
]
ARCHIVE_FOLDER = config.get('FILE_PATHS.archive_folder')

# –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–æ—Ä–º–∞—Ç–∞ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
FILE_NAME_PATTERN = re.compile(r"^\d{8}-\d{4}\.\w+$")


def log_folders_state(s3, folders, stage):
    logger.info(f"\nüìÇ –°–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∞–ø–æ–∫ ({stage}):")
    for folder in folders:
        files = list_files_in_folder(s3, folder)
        logger.info(f"- {folder}: {files}")


def load_config_public(s3):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç config_public.json –∏–∑ B2 –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–∞–∫ —Å–ª–æ–≤–∞—Ä—å.
    """
    try:
        local_path = CONFIG_PUBLIC_LOCAL_PATH
        logger.info(f"üîç s3 –ø–µ—Ä–µ–¥ .download_file(): {type(s3)}")
        s3.download_file(B2_BUCKET_NAME, CONFIG_PUBLIC_REMOTE_PATH, local_path)
        with open(local_path, 'r', encoding='utf-8') as file:
            config_data = json.load(file)
            logger.info(f"‚úÖ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ config_public.json: {config_data}")
            return config_data
    except FileNotFoundError:
        logger.error("‚ùå –§–∞–π–ª config_public.json –Ω–µ –Ω–∞–π–¥–µ–Ω –ª–æ–∫–∞–ª—å–Ω–æ.")
        return {}
    except ClientError as e:
        logger.error(f"Error loading config_public.json: {e.response['Error']['Message']}")
        return {}


def save_config_public(s3, data):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ config_public.json –ª–æ–∫–∞–ª—å–Ω–æ –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –µ–≥–æ –≤ B2.
    """
    try:
        with open(CONFIG_PUBLIC_LOCAL_PATH, 'w', encoding='utf-8') as file:
            json.dump(data, file, ensure_ascii=False, indent=4)
        s3.upload_file(CONFIG_PUBLIC_LOCAL_PATH, B2_BUCKET_NAME, CONFIG_PUBLIC_REMOTE_PATH)
    except Exception as e:
        logger.error(f"Error saving config_public.json: {e}")


def list_files_in_folder(s3, folder_prefix):
    try:
        response = s3.list_objects_v2(Bucket=B2_BUCKET_NAME, Prefix=folder_prefix)
        return [
            obj['Key'] for obj in response.get('Contents', [])
            if obj['Key'] != folder_prefix and not obj['Key'].endswith('.bzEmpty') and FILE_NAME_PATTERN.match(os.path.basename(obj['Key']))
        ]
    except ClientError as e:
        logger.error(f"Error listing files in {folder_prefix}: {e.response['Error']['Message']}")
        return []


def get_ready_groups(files):
    groups = {}
    for file_key in files:
        base_name = os.path.basename(file_key)
        if FILE_NAME_PATTERN.match(base_name):
            group_id = base_name.rsplit('.', 1)[0]
            groups.setdefault(group_id, []).append(base_name)
    ready_groups = []
    for group_id, file_list in groups.items():
        expected_files = [group_id + ext for ext in FILE_EXTENSIONS]
        if all(file in file_list for file in expected_files):
            ready_groups.append(group_id)
    return ready_groups


def handle_publish(s3, config_data):
    """–ü–µ—Ä–µ–º–µ—â–∞–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º–∏ generation_id –≤ –∞—Ä—Ö–∏–≤ B2, –ø–æ–∫–∞ —Å–ø–∏—Å–æ–∫ –Ω–µ —Å—Ç–∞–Ω–µ—Ç –ø—É—Å—Ç—ã–º."""
    while True:
        generation_ids = config_data.get("generation_id", [])
        if not generation_ids:
            logger.info("üìÇ –ù–µ—Ç generation_id –≤ config_public.json, –ø—É–±–ª–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
            return
        if isinstance(generation_ids, str):
            generation_ids = [generation_ids]
        logger.info(f"üìÇ –ù–∞–π–¥–µ–Ω—ã generation_id: {generation_ids}, –ø–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–∞–π–ª—ã –≤ –∞—Ä—Ö–∏–≤...")
        source_folders = ["444/", "555/", "666/"]
        archived_ids = []
        for generation_id in generation_ids:
            for folder in source_folders:
                files_to_move = list_files_in_folder(s3, folder)
                for file_key in files_to_move:
                    if generation_id in file_key:
                        archive_path = f"data/archive/{os.path.basename(file_key)}"
                        try:
                            s3.copy_object(Bucket=B2_BUCKET_NAME, CopySource={"Bucket": B2_BUCKET_NAME, "Key": file_key},
                                           Key=archive_path)
                            s3.delete_object(Bucket=B2_BUCKET_NAME, Key=file_key)
                            logger.info(f"‚úÖ –§–∞–π–ª {file_key} –ø–µ—Ä–µ–º–µ—â—ë–Ω –≤ –∞—Ä—Ö–∏–≤: {archive_path}")
                            if generation_id not in archived_ids:
                                archived_ids.append(generation_id)
                        except ClientError as e:
                            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–∏ {file_key}: {e.response['Error']['Message']}")
        config_data["generation_id"] = [gid for gid in generation_ids if gid not in archived_ids]
        if not config_data["generation_id"]:
            del config_data["generation_id"]
        save_config_public(s3, config_data)
        logger.info(f"‚úÖ –ê—Ä—Ö–∏–≤–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è: {archived_ids}")
        if not config_data.get("generation_id"):
            logger.info("üéâ –í—Å–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ –≥—Ä—É–ø–ø—ã –∑–∞–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω—ã, –∑–∞–≤–µ—Ä—à–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å.")
            break


def move_group(s3, src_folder, dst_folder, group_id):
    for ext in FILE_EXTENSIONS:
        src_key = f"{src_folder}{group_id}{ext}"
        dst_key = f"{dst_folder}{group_id}{ext}"
        try:
            s3.head_object(Bucket=B2_BUCKET_NAME, Key=src_key)
            s3.copy_object(Bucket=B2_BUCKET_NAME, CopySource={"Bucket": B2_BUCKET_NAME, "Key": src_key}, Key=dst_key)
            s3.delete_object(Bucket=B2_BUCKET_NAME, Key=src_key)
        except ClientError as e:
            if e.response['Error']['Code'] != "NoSuchKey":
                logger.error(f"Error moving {src_key}: {e.response['Error']['Message']}")


def process_folders(s3, folders):
    """
    –û–±—Ö–æ–¥–∏—Ç —Å–ø–∏—Å–æ–∫ –ø–∞–ø–æ–∫, –ø—ã—Ç–∞–µ—Ç—Å—è –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å "–≥–æ—Ç–æ–≤—ã–µ" –≥—Ä—É–ø–ø—ã –∏–∑ –ø–∞–ø–æ–∫ —Å –±–æ–ª–µ–µ –Ω–∏–∑–∫–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
    –≤ –ø–∞–ø–∫–∏ —Å –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–º, –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏.
    –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ –æ–±–Ω–æ–≤–ª—è–µ—Ç –∫–ª—é—á "empty" –≤ config_public.json.
    """
    empty_folders = set()
    changes_made = True
    while changes_made:
        changes_made = False
        for i in range(len(folders) - 1, 0, -1):
            src_folder = folders[i]
            dst_folder = folders[i - 1]
            if src_folder in empty_folders:
                continue
            src_files = list_files_in_folder(s3, src_folder)
            dst_files = list_files_in_folder(s3, dst_folder)
            src_ready = get_ready_groups(src_files)
            dst_ready = get_ready_groups(dst_files)
            for group_id in src_ready:
                if len(dst_ready) < 1:
                    move_group(s3, src_folder, dst_folder, group_id)
                    changes_made = True
            if not src_ready:
                empty_folders.add(src_folder)
    # –í—ã–∑–æ–≤ is_folder_empty —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏: (s3, bucket_name, folder_prefix)
    if is_folder_empty(s3, B2_BUCKET_NAME, "666/"):
        logger.info("‚ö†Ô∏è –ü–∞–ø–∫–∞ 666/ –ø—É—Å—Ç–∞. –ó–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
        subprocess.run(["python", os.path.join(config.get('FILE_PATHS.scripts_folder'), "generate_content.py")], check=True)
    else:
        logger.info("‚úÖ –í—Å–µ –ø–∞–ø–∫–∏ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã. –ó–∞–≤–µ—Ä—à–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å.")
    config_data = load_config_public(s3)
    config_data["empty"] = list(empty_folders)
    save_config_public(s3, config_data)
    logger.info(f"üìÇ –û–±–Ω–æ–≤–ª–µ–Ω—ã –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏ –≤ config_public.json: {config_data['empty']}")


def run_generate_media():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Å–∫—Ä–∏–ø—Ç generate_media.py –ø–æ –ª–æ–∫–∞–ª—å–Ω–æ–º—É –ø—É—Ç–∏."""
    try:
        scripts_folder = config.get("FILE_PATHS.scripts_folder", "scripts")
        script_path = os.path.join(scripts_folder, "generate_media.py")
        if not os.path.isfile(script_path):
            raise FileNotFoundError(f"–°–∫—Ä–∏–ø—Ç generate_media.py –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏: {script_path}")
        logger.info(f"üîÑ –ó–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞: {script_path}")
        subprocess.run(["python", script_path], check=True)
        logger.info(f"‚úÖ –°–∫—Ä–∏–ø—Ç {script_path} –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ.")
    except subprocess.CalledProcessError as e:
        handle_error("Script Execution Error", f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ —Å–∫—Ä–∏–ø—Ç–∞ {script_path}: {e}")
    except FileNotFoundError as e:
        handle_error("File Not Found Error", str(e))
    except Exception as e:
        handle_error("Unknown Error", f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Å–∫—Ä–∏–ø—Ç–∞ {script_path}: {e}")


def main():
    """–û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–µ–¥–∏–∞."""
    logger.info("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–µ–¥–∏–∞...")
    try:
        # –ß–∏—Ç–∞–µ–º config_gen.json
        logger.info(f"üìÑ –ß–∏—Ç–∞–µ–º config_gen.json: {CONFIG_GEN_PATH}")
        with open(CONFIG_GEN_PATH, 'r', encoding='utf-8') as file:
            config_gen = json.load(file)
        file_id = os.path.splitext(config_gen["generation_id"])[0]
        logger.info(f"üìÇ ID –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {file_id}")

        # –°–æ–∑–¥–∞—ë–º –∫–ª–∏–µ–Ω—Ç B2
        b2_client = get_b2_client()
        logger.info(f"‚ÑπÔ∏è –¢–∏–ø –æ–±—ä–µ–∫—Ç–∞ b2_client: {type(b2_client)}")
        logger.info(f"üöÄ generate_media.py –≤—ã–∑–≤–∞–Ω –∏–∑: {os.environ.get('GITHUB_WORKFLOW', '–ª–æ–∫–∞–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫')}")
        import inspect
        logger.info(f"üõ† –ü—Ä–æ–≤–µ—Ä–∫–∞ b2_client –≤ {__file__}, —Å—Ç—Ä–æ–∫–∞ {inspect.currentframe().f_lineno}: {type(b2_client)}")
        logger.info(f"üîç –ü–µ—Ä–µ–¥ –≤—ã–∑–æ–≤–æ–º download_file_from_b2(): {type(b2_client)}")
        download_file_from_b2(b2_client, CONFIG_PUBLIC_REMOTE_PATH, CONFIG_PUBLIC_LOCAL_PATH)
        logger.info(f"üîç –ü–æ—Å–ª–µ download_file_from_b2() b2_client: {type(b2_client)}")
        logger.info(f"üîç –¢–∏–ø –æ–±—ä–µ–∫—Ç–∞ b2_client –ø–µ—Ä–µ–¥ –≤—ã–∑–æ–≤–æ–º download_file_from_b2: {type(b2_client)}")

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∞–ø–æ–∫ —á–µ—Ä–µ–∑ process_folders
        logger.info("üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–∞–ø–æ–∫ —á–µ—Ä–µ–∑ process_folders()")
        process_folders(b2_client, FOLDERS)

        # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º config_public.json –ø–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—É—Å—Ç—ã—Ö –ø–∞–ø–æ–∫
        config_public = load_config_public(b2_client)
        logger.info(f"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π config_public.json: {config_public}")

        if "empty" in config_public and config_public["empty"]:
            target_folder = config_public["empty"][0]
            logger.info(f"üéØ –í—ã–±—Ä–∞–Ω–∞ –ø–∞–ø–∫–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏: {target_folder}")
        else:
            if not config_public.get("empty", []):
                logger.info("‚úÖ –ù–µ—Ç –ø—É—Å—Ç—ã—Ö –ø–∞–ø–æ–∫ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏. –ó–∞–≤–µ—Ä—à–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å.")
                return  # –ó–∞–≤–µ—Ä—à–∞–µ–º –±–µ–∑ –æ—à–∏–±–∫–∏

        if "empty" in config_public and config_public["empty"]:
            logger.info(f"üìÇ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏: {config_public['empty']}")
            for empty_folder in config_public["empty"]:
                if empty_folder == "666/":
                    logger.info("‚ö†Ô∏è –ü–∞–ø–∫–∞ 666/ –ø—É—Å—Ç–∞. –ó–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
                    subprocess.run(
                        ["python", os.path.join(config.get('FILE_PATHS.scripts_folder'), "generate_content.py")],
                        check=True)
                    import inspect
                    logger.info(f"üõ† –ü—Ä–æ–≤–µ—Ä–∫–∞ b2_client –≤ {__file__}, —Å—Ç—Ä–æ–∫–∞ {inspect.currentframe().f_lineno}: {type(b2_client)}")

        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≤—ã–∑–æ–≤: –≤—ã–∑—ã–≤–∞–µ–º move_to_archive –±–µ–∑ –ø–µ—Ä–µ–¥–∞—á–∏ b2_client
        if "generation_id" in config_public:
            for gen_id in config_public["generation_id"]:
                logger.info(f"üìÇ –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–∞–π–ª—ã –≥—Ä—É–ø–ø—ã {gen_id} –≤ –∞—Ä—Ö–∏–≤...")
                move_to_archive(b2_client, B2_BUCKET_NAME, gen_id, logger)
            config_public["generation_id"] = []
            save_config_public(b2_client, config_public)
            logger.info("‚úÖ –í—Å–µ generation_id —É–¥–∞–ª–µ–Ω—ã –∏–∑ config_public.json")
        else:
            logger.info("‚ö†Ô∏è –í config_public.json –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç generation_id. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–µ.")

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –≤ B2
        video_path = generate_mock_video(file_id)
        upload_to_b2(b2_client, target_folder, video_path)

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ config_public.json
        update_config_public(b2_client, target_folder)

        # –ü–æ—Å–ª–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∑–∞–ø—É—Å–∫–∞–µ–º b2_storage_manager.py –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–∞–ø–æ–∫
        logger.info("üîÑ –ó–∞–≤–µ—Ä—à–µ–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –º–µ–¥–∏–∞. –ó–∞–ø—É—Å–∫–∞–µ–º b2_storage_manager.py –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–∞–ø–æ–∫...")
        subprocess.run(["python", os.path.join(os.path.dirname(__file__), "b2_storage_manager.py")], check=True)

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ: {e}")
        handle_error(logger, "–û—à–∏–±–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞", e)


if __name__ == "__main__":
    main()
