import os
import json
import logging
import re

from botocore.exceptions import ClientError
from modules.api_clients import get_b2_client
from modules.logger import get_logger
from modules.error_handler import handle_error
from modules.utils import ensure_directory_exists
from modules.config_manager import ConfigManager
import subprocess  # –î–ª—è –∑–∞–ø—É—Å–∫–∞ –≤–Ω–µ—à–Ω–µ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞

# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ===
config = ConfigManager()
logger = get_logger("b2_storage_manager")


# === –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ===
B2_BUCKET_NAME = config.get('API_KEYS.b2.bucket_name')
CONFIG_PUBLIC_PATH = config.get('FILE_PATHS.config_public')
FILE_EXTENSIONS = ['.json', '.png', '.mp4']
FOLDERS = [
    config.get('FILE_PATHS.folder_444'),
    config.get('FILE_PATHS.folder_555'),
    config.get('FILE_PATHS.folder_666')
]
ARCHIVE_FOLDER = config.get('FILE_PATHS.archive_folder')

# –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–æ—Ä–º–∞—Ç–∞ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
FILE_NAME_PATTERN = re.compile(r"^\d{8}-\d{4}\.\w+$")

def log_folders_state(s3, folders, stage):
    logger.info(f"\nüìÇ –°–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∞–ø–æ–∫ ({stage}):")
    for folder in folders:
        files = list_files_in_folder(s3, folder)
        logger.info(f"- {folder}: {files}")


def load_config_public(s3):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç config_public.json –∏–∑ B2."""
    logger.info("üîÑ –ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ config_public.json...")
    try:
        local_path = os.path.basename(CONFIG_PUBLIC_PATH)
        logger.info(f"üì• –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å {CONFIG_PUBLIC_PATH} –≤ {local_path}...")
        s3.download_file(B2_BUCKET_NAME, CONFIG_PUBLIC_PATH, local_path)

        with open(local_path, 'r', encoding='utf-8') as file:
            config_data = json.load(file)
            logger.info(f"‚úÖ config_public.json —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –∏ –ø—Ä–æ—á–∏—Ç–∞–Ω: {config_data}")
            return config_data
    except FileNotFoundError:
        logger.warning("‚ö†Ô∏è –§–∞–π–ª config_public.json –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ.")
        return {}
    except ClientError as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ config_public.json: {e.response['Error']['Message']}")
        return {}
    except json.JSONDecodeError:
        logger.error("‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: config_public.json –ø–æ–≤—Ä–µ–∂–¥—ë–Ω.")
        return {}


def save_config_public(s3, config_data):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç config_public.json –≤ B2."""
    logger.info("üíæ –ù–∞—á–∞–ª–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è config_public.json...")
    try:
        local_path = os.path.basename(CONFIG_PUBLIC_PATH)

        with open(local_path, 'w', encoding='utf-8') as file:
            json.dump(config_data, file, ensure_ascii=False, indent=4)
        logger.info(f"‚úÖ config_public.json —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª—ë–Ω: {config_data}")

        logger.info(f"üì§ –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å {local_path} –æ–±—Ä–∞—Ç–Ω–æ –≤ B2...")
        s3.upload_file(local_path, B2_BUCKET_NAME, CONFIG_PUBLIC_PATH)
        logger.info("‚úÖ config_public.json —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ B2.")
    except FileNotFoundError:
        logger.error("‚ùå –û—à–∏–±–∫–∞: config_public.json –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è.")
    except ClientError as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ config_public.json –≤ B2: {e.response['Error']['Message']}")
    except Exception as e:
        logger.error(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ config_public.json: {e}")

def list_files_in_folder(s3, folder_prefix):
    try:
        response = s3.list_objects_v2(Bucket=B2_BUCKET_NAME, Prefix=folder_prefix)
        return [
            obj['Key'] for obj in response.get('Contents', [])
            if obj['Key'] != folder_prefix and not obj['Key'].endswith('.bzEmpty') and FILE_NAME_PATTERN.match(os.path.basename(obj['Key']))
        ]
    except ClientError as e:
        logger.error(f"Error listing files in {folder_prefix}: {e.response['Error']['Message']}")
        return []

def get_ready_groups(files):
    groups = {}
    for file_key in files:
        base_name = os.path.basename(file_key)
        if FILE_NAME_PATTERN.match(base_name):
            group_id = base_name.rsplit('.', 1)[0]
            groups.setdefault(group_id, []).append(base_name)

    ready_groups = []
    for group_id, file_list in groups.items():
        expected_files = [group_id + ext for ext in FILE_EXTENSIONS]
        if all(file in file_list for file in expected_files):
            ready_groups.append(group_id)

    return ready_groups

def handle_publish(s3, config_data):
    """–ü–µ—Ä–µ–º–µ—â–∞–µ—Ç –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ –∞—Ä—Ö–∏–≤ –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç config_public.json."""
    publish_folder = config_data.get("publish")
    if not publish_folder:
        logger.info("‚úÖ –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º handle_publish.")
        return

    logger.info(f"üîÑ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {publish_folder}")
    files = list_files_in_folder(s3, publish_folder)
    if not files:
        logger.info("‚úÖ –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è. –ó–∞–≤–µ—Ä—à–∞–µ–º handle_publish.")
        return

    for file_key in files:
        archive_key = file_key.replace(publish_folder, ARCHIVE_FOLDER)
        try:
            logger.info(f"üì§ –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ {file_key} –≤ –∞—Ä—Ö–∏–≤ {archive_key}...")
            s3.copy_object(Bucket=B2_BUCKET_NAME, CopySource={"Bucket": B2_BUCKET_NAME, "Key": file_key}, Key=archive_key)
            s3.delete_object(Bucket=B2_BUCKET_NAME, Key=file_key)
            logger.info(f"‚úÖ –§–∞–π–ª {file_key} —É—Å–ø–µ—à–Ω–æ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω.")
        except ClientError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏ {file_key}: {e.response['Error']['Message']}")

    config_data.pop("publish", None)
    save_config_public(s3, config_data)

def move_group(s3, src_folder, dst_folder, group_id):
    for ext in FILE_EXTENSIONS:
        src_key = f"{src_folder}{group_id}{ext}"
        dst_key = f"{dst_folder}{group_id}{ext}"
        try:
            s3.head_object(Bucket=B2_BUCKET_NAME, Key=src_key)
            s3.copy_object(Bucket=B2_BUCKET_NAME, CopySource={"Bucket": B2_BUCKET_NAME, "Key": src_key}, Key=dst_key)
            s3.delete_object(Bucket=B2_BUCKET_NAME, Key=src_key)
        except ClientError as e:
            if e.response['Error']['Code'] != "NoSuchKey":
                logger.error(f"Error moving {src_key}: {e.response['Error']['Message']}")

def process_folders(s3, folders):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–∞–ø–∫–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç—ã—Ö."""
    empty_folders = set()
    changes_made = True
    logger.info("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –ø–∞–ø–æ–∫...")

    while changes_made:
        changes_made = False
        for i in range(len(folders) - 1, 0, -1):
            src_folder = folders[i]
            dst_folder = folders[i - 1]

            if src_folder in empty_folders:
                continue

            src_files = list_files_in_folder(s3, src_folder)
            dst_files = list_files_in_folder(s3, dst_folder)

            src_ready = get_ready_groups(src_files)
            dst_ready = get_ready_groups(dst_files)

            logger.info(f"üìÇ –ê–Ω–∞–ª–∏–∑ –ø–∞–ø–∫–∏ {src_folder}: {len(src_ready)} –≥–æ—Ç–æ–≤—ã—Ö –≥—Ä—É–ø–ø")
            logger.info(f"üìÇ –ê–Ω–∞–ª–∏–∑ –ø–∞–ø–∫–∏ {dst_folder}: {len(dst_ready)} –≥–æ—Ç–æ–≤—ã—Ö –≥—Ä—É–ø–ø")

            for group_id in src_ready:
                if len(dst_ready) < 1:
                    logger.info(f"üì§ –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –≥—Ä—É–ø–ø—ã {group_id} –∏–∑ {src_folder} –≤ {dst_folder}")
                    move_group(s3, src_folder, dst_folder, group_id)
                    changes_made = True

            if not src_ready:
                logger.info(f"üìÇ –ü–∞–ø–∫–∞ {src_folder} —Ç–µ–ø–µ—Ä—å –ø—É—Å—Ç–∞—è.")
                empty_folders.add(src_folder)

    return list(empty_folders)

def main():
    try:
        s3 = get_b2_client()

        # –õ–æ–≥ –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–∞–ø–æ–∫
        log_folders_state(s3, FOLDERS, "–ù–∞—á–∞–ª–æ –ø—Ä–æ—Ü–µ—Å—Å–∞")

        config_data = load_config_public(s3)

        handle_publish(s3, config_data)

        empty_folders = process_folders(s3, FOLDERS)

        if empty_folders:
            config_data['empty'] = empty_folders
        else:
            config_data.pop('empty', None)

        save_config_public(s3, config_data)

        # –õ–æ–≥ –∫–æ–Ω–µ—á–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–∞–ø–æ–∫
        log_folders_state(s3, FOLDERS, "–ö–æ–Ω–µ—Ü –ø—Ä–æ—Ü–µ—Å—Å–∞")

        # –õ–æ–≥ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ config_public.json –≤ –∫–æ–Ω—Ü–µ –ø—Ä–æ—Ü–µ—Å—Å–∞
        logger.info(f"‚úÖ –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ config_public.json: {config_data}")

        # –ó–∞–ø—É—Å–∫ generate_content.py –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –ø—É—Å—Ç—ã—Ö –ø–∞–ø–æ–∫
        if empty_folders:
            logger.info("‚ö†Ô∏è –ù–∞–π–¥–µ–Ω—ã –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏. –ó–∞–ø—É—Å–∫ generate_content.py...")
            try:
                subprocess.run(["python", os.path.join(config.get('FILE_PATHS.scripts_folder'), "generate_content.py")], check=True)
                logger.info("‚úÖ –°–∫—Ä–∏–ø—Ç generate_content.py –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ.")
            except subprocess.CalledProcessError as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ generate_content.py: {e}")

    except Exception as e:
        handle_error(logger, e, "Error in main process")

if __name__ == "__main__":
    main()
