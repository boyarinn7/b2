import os
import json
import logging
import subprocess  # –î–ª—è –∑–∞–ø—É—Å–∫–∞ –≤–Ω–µ—à–Ω–µ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞
import re

from modules.utils import is_folder_empty, ensure_directory_exists, move_to_archive
from scripts.generate_media import download_file_from_b2
from botocore.exceptions import ClientError
from modules.api_clients import get_b2_client
from modules.logger import get_logger
from modules.error_handler import handle_error
from modules.config_manager import ConfigManager
from scripts.generate_media import download_file_from_b2, generate_mock_video
from scripts.generate_media import (
    download_file_from_b2, generate_mock_video,
    update_config_public, upload_to_b2
)

# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ===
config = ConfigManager()
logger = get_logger("b2_storage_manager")


# === –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ===
B2_BUCKET_NAME = config.get('API_KEYS.b2.bucket_name')
CONFIG_PUBLIC_PATH = config.get('FILE_PATHS.config_public')
CONFIG_GEN_PATH = os.path.abspath('config/config_gen.json')
CONFIG_PUBLIC_REMOTE_PATH = "config/config_public.json"
CONFIG_PUBLIC_LOCAL_PATH = os.path.abspath('config_public.json')
FILE_EXTENSIONS = ['.json', '.png', '.mp4']
FOLDERS = [
    config.get('FILE_PATHS.folder_444'),
    config.get('FILE_PATHS.folder_555'),
    config.get('FILE_PATHS.folder_666')
]
ARCHIVE_FOLDER = config.get('FILE_PATHS.archive_folder')


# –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–æ—Ä–º–∞—Ç–∞ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞

FILE_NAME_PATTERN = re.compile(r"^\d{8}-\d{4}\.\w+$")

def log_folders_state(s3, folders, stage):
    logger.info(f"\nüìÇ –°–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∞–ø–æ–∫ ({stage}):")
    for folder in folders:
        files = list_files_in_folder(s3, folder)
        logger.info(f"- {folder}: {files}")

def load_config_public(s3):
    try:
        local_path = os.path.basename(CONFIG_PUBLIC_PATH)
        s3.download_file(B2_BUCKET_NAME, CONFIG_PUBLIC_PATH, local_path)
        with open(local_path, 'r', encoding='utf-8') as file:
            config_data = json.load(file)
            logger.info(f"‚úÖ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ config_public.json: {config_data}")
            return config_data
    except FileNotFoundError:
        return {}
    except ClientError as e:
        logger.error(f"Error loading config_public.json: {e.response['Error']['Message']}")
        return {}

def save_config_public(s3, data):
    try:
        local_path = os.path.basename(CONFIG_PUBLIC_PATH)
        with open(local_path, 'w', encoding='utf-8') as file:
            json.dump(data, file, ensure_ascii=False, indent=4)
        s3.upload_file(local_path, B2_BUCKET_NAME, CONFIG_PUBLIC_PATH)
    except Exception as e:
        logger.error(f"Error saving config_public.json: {e}")

def list_files_in_folder(s3, folder_prefix):
    try:
        response = s3.list_objects_v2(Bucket=B2_BUCKET_NAME, Prefix=folder_prefix)
        return [
            obj['Key'] for obj in response.get('Contents', [])
            if obj['Key'] != folder_prefix and not obj['Key'].endswith('.bzEmpty') and FILE_NAME_PATTERN.match(os.path.basename(obj['Key']))
        ]
    except ClientError as e:
        logger.error(f"Error listing files in {folder_prefix}: {e.response['Error']['Message']}")
        return []

def get_ready_groups(files):
    groups = {}
    for file_key in files:
        base_name = os.path.basename(file_key)
        if FILE_NAME_PATTERN.match(base_name):
            group_id = base_name.rsplit('.', 1)[0]
            groups.setdefault(group_id, []).append(base_name)

    ready_groups = []
    for group_id, file_list in groups.items():
        expected_files = [group_id + ext for ext in FILE_EXTENSIONS]
        if all(file in file_list for file in expected_files):
            ready_groups.append(group_id)

    return ready_groups


def handle_publish(s3, config_data):
    """–ü–µ—Ä–µ–º–µ—â–∞–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º–∏ generation_id –≤ –∞—Ä—Ö–∏–≤ B2, –ø–æ–∫–∞ —Å–ø–∏—Å–æ–∫ –Ω–µ —Å—Ç–∞–Ω–µ—Ç –ø—É—Å—Ç—ã–º."""

    while True:
        generation_ids = config_data.get("generation_id", [])

        if not generation_ids:
            logger.info("üìÇ –ù–µ—Ç generation_id –≤ config_public.json, –ø—É–±–ª–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
            return  # ‚ùå –ï—Å–ª–∏ generation_id –ø—É—Å—Ç ‚Äì –ø—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–∞–µ—Ç—Å—è

        if isinstance(generation_ids, str):
            generation_ids = [generation_ids]  # –ü—Ä–∏–≤–æ–¥–∏–º –∫ —Å–ø–∏—Å–∫—É, –µ—Å–ª–∏ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞

        logger.info(f"üìÇ –ù–∞–π–¥–µ–Ω—ã generation_id: {generation_ids}, –ø–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–∞–π–ª—ã –≤ –∞—Ä—Ö–∏–≤...")

        # –ü–∞–ø–∫–∏, –≥–¥–µ –∏—â–µ–º —Ñ–∞–π–ª—ã —Å —ç—Ç–∏–º–∏ generation_id
        source_folders = ["444/", "555/", "666/"]

        archived_ids = []  # üîπ –°–ø–∏—Å–æ–∫ ID, –∫–æ—Ç–æ—Ä—ã–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –≤ –∞—Ä—Ö–∏–≤

        for generation_id in generation_ids:
            for folder in source_folders:
                files_to_move = list_files_in_folder(s3, folder)  # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤

                for file_key in files_to_move:
                    if generation_id in file_key:  # üè∑ –§–∏–ª—å—Ç—Ä—É–µ–º —Ñ–∞–π–ª—ã –ø–æ generation_id
                        archive_path = f"data/archive/{os.path.basename(file_key)}"

                        try:
                            # üì§ –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–∞–π–ª –≤ –∞—Ä—Ö–∏–≤
                            s3.copy_object(Bucket=B2_BUCKET_NAME, CopySource={"Bucket": B2_BUCKET_NAME, "Key": file_key},
                                           Key=archive_path)
                            s3.delete_object(Bucket=B2_BUCKET_NAME, Key=file_key)
                            logger.info(f"‚úÖ –§–∞–π–ª {file_key} –ø–µ—Ä–µ–º–µ—â—ë–Ω –≤ –∞—Ä—Ö–∏–≤: {archive_path}")

                            if generation_id not in archived_ids:
                                archived_ids.append(generation_id)  # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º, —á—Ç–æ —ç—Ç–æ—Ç ID –∑–∞–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω

                        except ClientError as e:
                            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–∏ {file_key}: {e.response['Error']['Message']}")

        # üè∑ –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ –∑–∞–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ generation_id –∏–∑ —Å–ø–∏—Å–∫–∞
        config_data["generation_id"] = [gid for gid in generation_ids if gid not in archived_ids]

        # ‚úÖ –ï—Å–ª–∏ —Å–ø–∏—Å–æ–∫ generation_id –ø—É—Å—Ç ‚Äì —É–¥–∞–ª—è–µ–º –∫–ª—é—á
        if not config_data["generation_id"]:
            del config_data["generation_id"]

        # üì§ –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π config_public.json –≤ B2
        save_config_public(s3, config_data)
        logger.info(f"‚úÖ –ê—Ä—Ö–∏–≤–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è: {archived_ids}")

        # üîÑ –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Å—Ç–∞–ª–∏—Å—å –ª–∏ generation_id, –µ—Å–ª–∏ –Ω–µ—Ç ‚Äì –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞
        if not config_data.get("generation_id"):
            logger.info("üéâ –í—Å–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ –≥—Ä—É–ø–ø—ã –∑–∞–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω—ã, –∑–∞–≤–µ—Ä—à–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å.")
            break


def move_group(s3, src_folder, dst_folder, group_id):
    for ext in FILE_EXTENSIONS:
        src_key = f"{src_folder}{group_id}{ext}"
        dst_key = f"{dst_folder}{group_id}{ext}"
        try:
            s3.head_object(Bucket=B2_BUCKET_NAME, Key=src_key)
            s3.copy_object(Bucket=B2_BUCKET_NAME, CopySource={"Bucket": B2_BUCKET_NAME, "Key": src_key}, Key=dst_key)
            s3.delete_object(Bucket=B2_BUCKET_NAME, Key=src_key)
        except ClientError as e:
            if e.response['Error']['Code'] != "NoSuchKey":
                logger.error(f"Error moving {src_key}: {e.response['Error']['Message']}")

def process_folders(s3, folders):
    empty_folders = set()
    changes_made = True

    while changes_made:
        changes_made = False
        for i in range(len(folders) - 1, 0, -1):
            src_folder = folders[i]
            dst_folder = folders[i - 1]

            if src_folder in empty_folders:
                continue

            src_files = list_files_in_folder(s3, src_folder)
            dst_files = list_files_in_folder(s3, dst_folder)

            src_ready = get_ready_groups(src_files)
            dst_ready = get_ready_groups(dst_files)

            for group_id in src_ready:
                if len(dst_ready) < 1:
                    move_group(s3, src_folder, dst_folder, group_id)
                    changes_made = True

            if not src_ready:
                empty_folders.add(src_folder)

    # ‚úÖ –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ 666/ –ø—É—Å—Ç–∞—è, –∑–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    if is_folder_empty(s3, "666/"):
        logger.info("‚ö†Ô∏è –ü–∞–ø–∫–∞ 666/ –ø—É—Å—Ç–∞. –ó–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
        subprocess.run(["python", os.path.join(config.get('FILE_PATHS.scripts_folder'), "generate_content.py")], check=True)

    else:
        logger.info("‚úÖ –í—Å–µ –ø–∞–ø–∫–∏ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã. –ó–∞–≤–µ—Ä—à–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å.")

    # –û–±–Ω–æ–≤–ª—è–µ–º config_public.json –ø—É—Å—Ç—ã–º–∏ –ø–∞–ø–∫–∞–º–∏
    config_data = load_config_public(s3)
    config_data["empty"] = list(empty_folders)  # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏
    save_config_public(s3, config_data)
    logger.info(f"üìÇ –û–±–Ω–æ–≤–ª–µ–Ω—ã –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏ –≤ config_public.json: {config_data['empty']}")


def main():
    """–û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–µ–¥–∏–∞."""
    logger.info("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–µ–¥–∏–∞...")
    try:
        # –ß–∏—Ç–∞–µ–º config_gen.json
        logger.info(f"üìÑ –ß–∏—Ç–∞–µ–º config_gen.json: {CONFIG_GEN_PATH}")
        with open(CONFIG_GEN_PATH, 'r', encoding='utf-8') as file:
            config_gen = json.load(file)

        file_id = os.path.splitext(config_gen["generation_id"])[0]
        logger.info(f"üìÇ ID –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {file_id}")

        # –°–æ–∑–¥–∞—ë–º –∫–ª–∏–µ–Ω—Ç B2
        b2_client = get_b2_client()
        logger.info(f"‚ÑπÔ∏è –¢–∏–ø –æ–±—ä–µ–∫—Ç–∞ b2_client: {type(b2_client)}")

        # –õ–æ–≥–∏—Ä—É–µ–º –≤—ã–∑–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
        logger.info(f"üöÄ generate_media.py –≤—ã–∑–≤–∞–Ω –∏–∑: {os.environ.get('GITHUB_WORKFLOW', '–ª–æ–∫–∞–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫')}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º config_public.json
        logger.info(f"üîç –ü–µ—Ä–µ–¥ –≤—ã–∑–æ–≤–æ–º download_file_from_b2(): {type(b2_client)}")
        download_file_from_b2(b2_client, CONFIG_PUBLIC_REMOTE_PATH, CONFIG_PUBLIC_LOCAL_PATH)
        config_public = load_config_public(CONFIG_PUBLIC_LOCAL_PATH)
        logger.info(f"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π config_public.json: {config_public}")

        if "empty" in config_public and config_public["empty"]:
            target_folder = config_public["empty"][0]  # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—É—é –ø—É—Å—Ç—É—é –ø–∞–ø–∫—É
            logger.info(f"üéØ –í—ã–±—Ä–∞–Ω–∞ –ø–∞–ø–∫–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏: {target_folder}")
        else:
            logger.error("‚ùå –ù–µ—Ç –ø—É—Å—Ç—ã—Ö –ø–∞–ø–æ–∫ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞.")
            return  # –ü—Ä–µ—Ä—ã–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ, –µ—Å–ª–∏ –Ω–µ—Ç –ø–∞–ø–æ–∫

        if "empty" in config_public and config_public["empty"]:
            logger.info(f"üìÇ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏: {config_public['empty']}")
            for empty_folder in config_public["empty"]:
                if empty_folder == "666/":
                    logger.info("‚ö†Ô∏è –ü–∞–ø–∫–∞ 666/ –ø—É—Å—Ç–∞. –ó–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
                    subprocess.run(
                        ["python", os.path.join(config.get('FILE_PATHS.scripts_folder'), "generate_content.py")],
                        check=True)

        if "generation_id" in config_public:
            for gen_id in config_public["generation_id"]:
                logger.info(f"üìÇ –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–∞–π–ª—ã –≥—Ä—É–ø–ø—ã {gen_id} –≤ –∞—Ä—Ö–∏–≤...")
                move_to_archive(b2_client, B2_BUCKET_NAME, gen_id, logger)  # ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≤—ã–∑–æ–≤

                # –£–¥–∞–ª—è–µ–º generation_id, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –∑–∞–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω—ã
            config_public["generation_id"] = []
            save_config_public(CONFIG_PUBLIC_LOCAL_PATH, config_public)  # ‚úÖ –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
            logger.info("‚úÖ –í—Å–µ generation_id —É–¥–∞–ª–µ–Ω—ã –∏–∑ config_public.json")

        else:
            logger.info("‚ö†Ô∏è –í config_public.json –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç generation_id. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–µ.")

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –≤ B2
        video_path = generate_mock_video(file_id)
        upload_to_b2(b2_client, target_folder, video_path)

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ config_public.json
        update_config_public(b2_client, target_folder)

        # üîÑ –ü–æ—Å–ª–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∑–∞–ø—É—Å–∫–∞–µ–º b2_storage_manager.py
        logger.info("üîÑ –ó–∞–≤–µ—Ä—à–µ–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –º–µ–¥–∏–∞. –ó–∞–ø—É—Å–∫–∞–µ–º b2_storage_manager.py –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–∞–ø–æ–∫...")
        subprocess.run(["python", os.path.join(os.path.dirname(__file__), "b2_storage_manager.py")], check=True)

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ: {e}")
        handle_error(logger, "–û—à–∏–±–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞", e)


if __name__ == "__main__":
    main()
