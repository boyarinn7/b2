# core/scripts/itself.py

import os
import json
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from modules.api_clients import get_b2_client
from modules.logger import get_logger
from modules.error_handler import handle_error
from modules.utils import ensure_directory_exists, validate_json_structure
from modules.config_manager import ConfigManager
from botocore.exceptions import ClientError

# === Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ===
config = ConfigManager()
logger = get_logger("itself")
s3 = get_b2_client()

# === ÐšÐ¾Ð½ÑÑ‚Ð°Ð½Ñ‚Ñ‹ ===
B2_BUCKET_NAME = config.get('API_KEYS.b2.bucket_name')
ARCHIVE_FOLDERS = config.get('FILE_PATHS.archive_folder')
SUCCESS_THRESHOLD = config.get('LEARNING.success_threshold', 8)
DELETE_THRESHOLD = config.get('LEARNING.delete_threshold', 3)
MAX_WORKERS = config.get('LEARNING.max_workers', 5)


def list_files(folder):
    """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð¸Ð· Ð¿Ð°Ð¿ÐºÐ¸ Ð½Ð° B2."""
    try:
        response = s3.list_objects_v2(Bucket=B2_BUCKET_NAME, Prefix=folder)
        return [obj["Key"] for obj in response.get("Contents", []) if obj["Key"].endswith("-metadata.json")]
    except ClientError as e:
        handle_error("B2 List Files Error", e)


def load_meta_file(file_key):
    """Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ Ð¸ Ð²Ð°Ð»Ð¸Ð´Ð¸Ñ€ÑƒÐµÑ‚ Ð¼ÐµÑ‚Ð°-Ñ„Ð°Ð¹Ð»."""
    required_fields = [
        "topic", "text", "likes", "shares", "views",
        "ocp", "seo_keywords", "date", "comments", "has_media"
    ]
    local_file = os.path.basename(file_key)
    try:
        s3.download_file(B2_BUCKET_NAME, file_key, local_file)
        with open(local_file, "r", encoding="utf-8") as f:
            content = json.load(f)

        validate_json_structure(content, required_fields)
        return content
    except (json.JSONDecodeError, ClientError) as e:
        handle_error("Meta File Load Error", e)
    finally:
        if os.path.exists(local_file):
            os.remove(local_file)


def calculate_rating(meta):
    """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÑ‚ Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¼ÐµÑ‚Ñ€Ð¸Ðº."""
    try:
        likes = meta.get("likes", 0)
        comments = len(meta.get("comments", []))
        shares = meta.get("shares", 0)
        views = meta.get("views", 1)
        engagement_rate = (likes + comments + shares) / views if views > 0 else 0

        base_score = (likes + comments + shares) / (datetime.now() - datetime.strptime(meta["date"], "%Y-%m-%d")).days
        rating = round(
            base_score +
            (meta.get("topic_score", 0) * 0.2) +
            (meta.get("text_score", 0) * 0.3) +
            (engagement_rate * 0.2),
            2
        )
        logger.info(f"ðŸ“Š Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³: {rating}")
        return rating
    except Exception as e:
        handle_error("Rating Calculation Error", e)


def move_file(file_key, dest_folder):
    """ÐŸÐµÑ€ÐµÐ¼ÐµÑ‰Ð°ÐµÑ‚ Ñ„Ð°Ð¹Ð» Ð² ÑƒÐºÐ°Ð·Ð°Ð½Ð½ÑƒÑŽ Ð¿Ð°Ð¿ÐºÑƒ."""
    try:
        src_key = file_key
        dst_key = f"{dest_folder}/{os.path.basename(file_key)}"
        s3.copy_object(Bucket=B2_BUCKET_NAME, CopySource={"Bucket": B2_BUCKET_NAME, "Key": src_key}, Key=dst_key)
        s3.delete_object(Bucket=B2_BUCKET_NAME, Key=src_key)
        logger.info(f"âœ… Ð¤Ð°Ð¹Ð» {src_key} Ð¿ÐµÑ€ÐµÐ¼ÐµÑ‰Ñ‘Ð½ Ð² {dest_folder}.")
    except ClientError as e:
        handle_error("File Move Error", e)


def process_file(file_key):
    """ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð»."""
    meta = load_meta_file(file_key)
    if not meta:
        return

    rating = calculate_rating(meta)
    if rating > SUCCESS_THRESHOLD:
        move_file(file_key, f"{ARCHIVE_FOLDERS}/successful")
    elif rating < DELETE_THRESHOLD:
        move_file(file_key, f"{ARCHIVE_FOLDERS}/pending_delete")


def update_archive():
    """ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÑ‚ Ð°Ñ€Ñ…Ð¸Ð² Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ„Ð°Ð¹Ð»Ð¾Ð²."""
    try:
        in_progress_files = list_files(f"{ARCHIVE_FOLDERS}/in_progress")
        if not in_progress_files:
            logger.info("âœ… ÐÐµÑ‚ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸.")
            return

        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            executor.map(process_file, in_progress_files)
        logger.info("ðŸ ÐÑ€Ñ…Ð¸Ð² ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð¾Ð±Ð½Ð¾Ð²Ð»Ñ‘Ð½.")
    except Exception as e:
        handle_error("Archive Update Error", e)


def main():
    """ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð°Ñ€Ñ…Ð¸Ð²Ð¾Ð¼."""
    logger.info("ðŸ”„ Ð—Ð°Ð¿ÑƒÑÐº Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ° ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð°Ñ€Ñ…Ð¸Ð²Ð¾Ð¼...")
    update_archive()
    logger.info("ðŸ ÐŸÑ€Ð¾Ñ†ÐµÑÑ Ð·Ð°Ð²ÐµÑ€ÑˆÑ‘Ð½ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾.")


# === Ð¢Ð¾Ñ‡ÐºÐ° Ð²Ñ…Ð¾Ð´Ð° ===
if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        logger.info("ðŸ›‘ ÐŸÑ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð° Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¼.")
