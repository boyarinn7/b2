# -*- coding: utf-8 -*-
# –í —Ñ–∞–π–ª–µ scripts/generate_content.py

import json
import os
import sys
import openai # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥—É–ª—å
import re
import boto3
import io
import random
import argparse
from datetime import datetime, timezone
import shutil
from pathlib import Path
import logging # –î–æ–±–∞–≤–ª—è–µ–º logging
import httpx # <-- –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç httpx

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º ClientError –∏–∑ botocore
try:
    from botocore.exceptions import ClientError
except ImportError:
    ClientError = Exception
    print("Warning: Could not import ClientError from botocore.")

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
BASE_DIR = Path(__file__).resolve().parent.parent
if str(BASE_DIR) not in sys.path:
    sys.path.append(str(BASE_DIR))

# --- –ò–º–ø–æ—Ä—Ç –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –º–æ–¥—É–ª–µ–π ---
try:
    from modules.config_manager import ConfigManager
    from modules.logger import get_logger
    from modules.error_handler import handle_error
    from modules.utils import ensure_directory_exists, load_b2_json, save_b2_json, load_json_config
    from modules.api_clients import get_b2_client
except ModuleNotFoundError as e:
     print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω—ã –º–æ–¥—É–ª–∏ –ø—Ä–æ–µ–∫—Ç–∞ –≤ generate_content: {e}", file=sys.stderr)
     sys.exit(1)
except ImportError as e:
     # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ load_json_config
     if 'load_json_config' in str(e):
        print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –û—à–∏–±–∫–∞: –§—É–Ω–∫—Ü–∏—è 'load_json_config' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ 'modules.utils'.", file=sys.stderr)
     else:
        print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è/–∫–ª–∞—Å—Å –≤ –º–æ–¥—É–ª—è—Ö: {e}", file=sys.stderr)
     sys.exit(1)

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–≥–≥–µ—Ä–∞ ---
logger = get_logger("generate_content")

# --- –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞ OpenAI (–±—É–¥–µ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –≤ call_openai) ---
openai_client_instance = None

# --- –§—É–Ω–∫—Ü–∏—è –≤—ã–∑–æ–≤–∞ OpenAI API (–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–∞ –∏–∑ iid_local_tester.py - –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï v3) ---
def call_openai(prompt_text: str, prompt_config_key: str, use_json_mode=False, temperature_override=None, max_tokens_override=None, config_manager_instance=None, prompts_config_data_instance=None):
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –≤—ã–∑–æ–≤ OpenAI API (–≤–µ—Ä—Å–∏–∏ >=1.0), –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—è –∫–ª–∏–µ–Ω—Ç –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏,
    –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π JSON –∏–ª–∏ —Å—Ç—Ä–æ–∫—É.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ prompts_config.json.
    """
    global openai_client_instance # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞

    # --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –≤—ã–∑–æ–≤–µ ---
    if not openai_client_instance:
        api_key_local = os.getenv("OPENAI_API_KEY")
        if not api_key_local:
            logger.error("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω–∞!")
            raise RuntimeError("OpenAI API key not found.") # –ü—Ä–µ—Ä—ã–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ

        try:
            if openai and hasattr(openai, 'OpenAI'):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø—Ä–æ–∫—Å–∏ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
                http_proxy = os.getenv("HTTP_PROXY")
                https_proxy = os.getenv("HTTPS_PROXY")
                proxies_dict = {}
                if http_proxy: proxies_dict["http://"] = http_proxy
                if https_proxy: proxies_dict["https://"] = https_proxy

                # –°–æ–∑–¥–∞–µ–º httpx_client –í–°–ï–ì–î–ê, –Ω–æ –ø–µ—Ä–µ–¥–∞–µ–º proxies —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
                if proxies_dict:
                    logger.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–∫—Å–∏ –¥–ª—è OpenAI: {proxies_dict}")
                    http_client = httpx.Client(proxies=proxies_dict)
                else:
                    logger.info("–ü—Ä–æ–∫—Å–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã, —Å–æ–∑–¥–∞–µ–º httpx.Client –±–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–∞ proxies.")
                    http_client = httpx.Client() # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±–µ–∑ proxies

                # –ü–µ—Ä–µ–¥–∞–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–π http_client –≤ OpenAI
                openai_client_instance = openai.OpenAI(api_key=api_key_local, http_client=http_client)
                logger.info("‚úÖ –ö–ª–∏–µ–Ω—Ç OpenAI (>1.0) –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")

            else:
                logger.error("‚ùå –ú–æ–¥—É–ª—å/–∫–ª–∞—Å—Å openai.OpenAI –Ω–µ –Ω–∞–π–¥–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –≤–µ—Ä—Å–∏—è >= 1.0.")
                raise ImportError("openai.OpenAI class not found.")
        except Exception as init_err:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞ OpenAI: {init_err}", exc_info=True)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å–≤—è–∑–∞–Ω–∞ –ª–∏ –æ—à–∏–±–∫–∞ —Å 'proxies' —Å–Ω–æ–≤–∞
            if "got an unexpected keyword argument 'proxies'" in str(init_err):
                logger.error("!!! –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –æ—à–∏–±–∫–∞ 'unexpected keyword argument proxies'. –ü—Ä–æ–±–ª–µ–º–∞ –≥–ª—É–±–∂–µ, –≤–æ–∑–º–æ–∂–Ω–æ, –≤ httpx –∏–ª–∏ –æ–∫—Ä—É–∂–µ–Ω–∏–∏.")
            raise RuntimeError(f"Failed to initialize OpenAI client: {init_err}") from init_err
    # --- –ö–æ–Ω–µ—Ü –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞ ---

    if not config_manager_instance:
        logger.error("‚ùå –≠–∫–∑–µ–º–ø–ª—è—Ä ConfigManager –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω –≤ call_openai.")
        return None # –ò–ª–∏ raise exception
    if not prompts_config_data_instance:
        logger.error("‚ùå –î–∞–Ω–Ω—ã–µ prompts_config –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã –≤ call_openai.")
        return None # –ò–ª–∏ raise exception

    openai_model = config_manager_instance.get("OPENAI_SETTINGS.model", "gpt-4o")

    try:
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø—Ä–æ–º–ø—Ç–∞
        keys = prompt_config_key.split('.')
        prompt_settings = prompts_config_data_instance
        for key in keys: prompt_settings = prompt_settings.get(key, {})
        if not isinstance(prompt_settings, dict):
            logger.warning(f"–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è '{prompt_config_key}' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã/–Ω–µ —Å–ª–æ–≤–∞—Ä—å. –î–µ—Ñ–æ–ª—Ç—ã."); prompt_settings = {}

        default_temp = 0.7; default_max_tokens = 1500
        temp = float(temperature_override if temperature_override is not None else prompt_settings.get('temperature', default_temp))
        max_tokens = int(max_tokens_override if max_tokens_override is not None else prompt_settings.get('max_tokens', default_max_tokens))

        logger.info(f"üîé –í—ã–∑–æ–≤ OpenAI (–ö–ª—é—á: {prompt_config_key}, –ú–æ–¥–µ–ª—å: {openai_model}, JSON={use_json_mode}, t={temp:.2f}, max_tokens={max_tokens})...")

        messages = [{"role": "system", "content": "You are a helpful AI assistant specializing in historical content generation. Follow user instructions precisely and respond ONLY in the specified format (e.g., JSON) without any extra text."},
                    {"role": "user", "content": prompt_text}]

        request_params = { "model": openai_model, "messages": messages, "max_tokens": max_tokens, "temperature": temp }
        if use_json_mode: request_params["response_format"] = {"type": "json_object"}

        response = openai_client_instance.chat.completions.create(**request_params)

        if response.choices and response.choices[0].message and response.choices[0].message.content:
            response_content = response.choices[0].message.content.strip()
            logger.debug(f"–°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç OpenAI: {response_content[:500]}...")
            # --- –ù–ê–ß–ê–õ–û –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø ---
            # –í—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏ —É–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—É—é Markdown –æ–±–µ—Ä—Ç–∫—É JSON
            if response_content.startswith("```json"):
                logger.debug("–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –æ–±–µ—Ä—Ç–∫–∞ ```json –≤ –æ—Ç–≤–µ—Ç–µ, —É–¥–∞–ª—è–µ–º...")
                response_content = response_content[7:]  # –£–±–∏—Ä–∞–µ–º ```json\n
                # –£–±–∏—Ä–∞–µ–º ``` –≤ –∫–æ–Ω—Ü–µ, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
                if response_content.endswith("```"):
                    response_content = response_content[:-3]
                response_content = response_content.strip()  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –ø–æ –∫—Ä–∞—è–º
                logger.debug(f"–û—Ç–≤–µ—Ç –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –æ–±–µ—Ä—Ç–∫–∏: {response_content[:500]}...")
            elif response_content.startswith("```") and response_content.endswith("```"):
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ª—É—á–∞—è, –µ—Å–ª–∏ –æ–±–µ—Ä—Ç–∫–∞ –ø—Ä–æ—Å—Ç–æ ``` –±–µ–∑ 'json'
                logger.debug("–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –æ–±–µ—Ä—Ç–∫–∞ ``` –≤ –æ—Ç–≤–µ—Ç–µ, —É–¥–∞–ª—è–µ–º...")
                response_content = response_content[3:-3].strip()
                logger.debug(f"–û—Ç–≤–µ—Ç –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –æ–±–µ—Ä—Ç–∫–∏ ```: {response_content[:500]}...")
            # --- –ö–û–ù–ï–¶ –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø ---

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–æ–∑–º–æ–∂–Ω–æ–π –æ–±–µ—Ä—Ç–∫–∏ ```json
         #   if use_json_mode and response_content.startswith("```json"):
         #        response_content = response_content[7:] # –£–±–∏—Ä–∞–µ–º ```json\n
         #        response_content = response_content[:-3] if response_content.endswith("```") else response_content # –£–±–∏—Ä–∞–µ–º ``` –≤ –∫–æ–Ω—Ü–µ
         #        response_content = response_content.strip()

            # –ï—Å–ª–∏ –Ω—É–∂–µ–Ω JSON, –ø—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
            if use_json_mode:
                try:
                    parsed_json = json.loads(response_content)
                    logger.debug("–û—Ç–≤–µ—Ç OpenAI —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω –∫–∞–∫ JSON.")
                    return parsed_json
                except json.JSONDecodeError as json_e:
                    logger.error(f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ OpenAI: {json_e}\n–û—Ç–≤–µ—Ç: {response_content}")
                    return None # –í–æ–∑–≤—Ä–∞—â–∞–µ–º None –ø—Ä–∏ –æ—à–∏–±–∫–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON
            else:
                # –ï—Å–ª–∏ JSON –Ω–µ –Ω—É–∂–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ —Å—Ç—Ä–æ–∫—É
                return response_content
        else:
            logger.error("‚ùå OpenAI API –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π/–Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç.");
            logger.debug(f"–ó–∞–ø—Ä–æ—Å: {messages}")
            return None

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –æ—à–∏–±–æ–∫ OpenAI
    except openai.AuthenticationError as e: logger.exception(f"–û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ OpenAI: {e}"); return None
    except openai.RateLimitError as e: logger.exception(f"–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ OpenAI: {e}"); return None
    except openai.APIConnectionError as e: logger.exception(f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å API OpenAI: {e}"); return None
    except openai.APIStatusError as e: logger.exception(f"–û—à–∏–±–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ API OpenAI: {e.status_code} - {e.response}"); return None
    except openai.BadRequestError as e: logger.exception(f"–û—à–∏–±–∫–∞ –Ω–µ–≤–µ—Ä–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ OpenAI: {e}"); return None
    except openai.OpenAIError as e: logger.exception(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ API OpenAI: {e}"); return None
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥—Ä—É–≥–∏—Ö –∏—Å–∫–ª—é—á–µ–Ω–∏–π
    except Exception as e: logger.exception(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ call_openai: {e}"); return None


# --- –§—É–Ω–∫—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ B2 (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ---
def save_content_to_b2(folder, content_dict, generation_id, config_manager_instance):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ª–æ–≤–∞—Ä—å content_dict –∫–∞–∫ JSON –≤ —É–∫–∞–∑–∞–Ω–Ω—É—é –ø–∞–ø–∫—É B2."""
    logger.info(f"–í—ã–∑–æ–≤ save_content_to_b2 –¥–ª—è ID: {generation_id}")
    config = config_manager_instance
    s3 = get_b2_client()
    if not s3: logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∫–ª–∏–µ–Ω—Ç B2."); return False
    bucket_name = config.get("API_KEYS.b2.bucket_name")
    if not bucket_name: logger.error("‚ùå –ò–º—è –±–∞–∫–µ—Ç–∞ B2 –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."); return False
    if not generation_id: logger.error("‚ùå Generation ID –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω."); return False
    if not isinstance(content_dict, dict): logger.error("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ —Å–ª–æ–≤–∞—Ä—å."); return False

    clean_base_id = generation_id.replace(".json", "")
    s3_key = f"{folder.rstrip('/')}/{clean_base_id}.json"
    timestamp_suffix = datetime.utcnow().strftime("%Y%m%d%H%M%S%f")
    local_temp_path = f"{clean_base_id}_content_temp_{timestamp_suffix}.json"
    logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ {clean_base_id} –≤ B2 –∫–∞–∫ {s3_key} —á–µ—Ä–µ–∑ {local_temp_path}...")

    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–µ–π (–æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –±—ã–ª–æ)
        required_keys = ["topic", "content", "sarcasm", "script", "first_frame_description",
                         "creative_brief", "final_mj_prompt", "final_runway_prompt"]
        missing_keys = [key for key in required_keys if key not in content_dict]
        null_keys = [key for key in required_keys if key in content_dict and content_dict[key] is None]
        if missing_keys: logger.warning(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–ª—é—á–∏: {missing_keys}.")
        if null_keys: logger.warning(f"‚ö†Ô∏è –ö–ª—é—á–∏ —Å null: {null_keys}.")

        ensure_directory_exists(local_temp_path) # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –ø–µ—Ä–µ–¥ –∑–∞–ø–∏—Å—å—é
        with open(local_temp_path, 'w', encoding='utf-8') as f:
            json.dump(content_dict, f, ensure_ascii=False, indent=4)
        logger.debug(f"–í—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {local_temp_path} —Å–æ–∑–¥–∞–Ω.")
        s3.upload_file(local_temp_path, bucket_name, s3_key)
        logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ –¥–ª—è {clean_base_id} —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ B2: {s3_key}")
        return True
    except Exception as e:
        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å {clean_base_id} –≤ B2: {e}", exc_info=True)
        return False
    finally:
        if os.path.exists(local_temp_path):
            try: os.remove(local_temp_path); logger.debug(f"–í—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {local_temp_path} —É–¥–∞–ª–µ–Ω.")
            except OSError as remove_err: logger.warning(f"–ù–µ —É–¥–∞–ª–∏—Ç—å {local_temp_path}: {remove_err}")

# --- –ö–õ–ê–°–° –ì–ï–ù–ï–†–ê–¢–û–†–ê –ö–û–ù–¢–ï–ù–¢–ê ---
class ContentGenerator:
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞."""
        self.logger = logger
        self.config = ConfigManager()

        self.creative_config_data = self._load_additional_config('FILE_PATHS.creative_config', 'Creative Config')
        self.prompts_config_data = self._load_additional_config('FILE_PATHS.prompts_config', 'Prompts Config')

        self.topic_threshold = self.config.get('GENERATE.topic_threshold', 7)
        self.text_threshold = self.config.get('GENERATE.text_threshold', 8)
        self.max_attempts = self.config.get('GENERATE.max_attempts', 1)
        self.adaptation_enabled = self.config.get('GENERATE.adaptation_enabled', False)
        self.adaptation_params = self.config.get('GENERATE.adaptation_parameters', {})
        self.content_output_path = self.config.get('FILE_PATHS.content_output_path', 'generated_content.json')

        # --- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø OpenAI –£–î–ê–õ–ï–ù–ê –û–¢–°–Æ–î–ê ---

        self.b2_client = get_b2_client()
        if not self.b2_client: self.logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å B2 –∫–ª–∏–µ–Ω—Ç.")

        self.tracker_path_rel = self.config.get("FILE_PATHS.tracker_path", "data/topics_tracker.json")
        self.failsafe_path_rel = self.config.get("FILE_PATHS.failsafe_path", "config/FailSafeVault.json")

        self.tracker_path_abs = BASE_DIR / self.tracker_path_rel
        self.failsafe_path_abs = BASE_DIR / self.failsafe_path_rel
        self.b2_bucket_name = self.config.get("API_KEYS.b2.bucket_name", "default-bucket")
        if not self.b2_bucket_name or self.b2_bucket_name == "default-bucket":
            logger.warning("–ò–º—è –±–∞–∫–µ—Ç–∞ B2 –Ω–µ –∑–∞–¥–∞–Ω–æ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é!")

    def _load_additional_config(self, config_key, config_name):
        """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–ø. –∫–æ–Ω—Ñ–∏–≥–æ–≤."""
        config_path_str = self.config.get(config_key)
        if not config_path_str: self.logger.error(f"‚ùå –ü—É—Ç—å –∫ {config_name} –Ω–µ –Ω–∞–π–¥–µ–Ω (–∫–ª—é—á: {config_key})."); return None
        config_path = BASE_DIR / config_path_str
        data = load_json_config(str(config_path))
        if data: self.logger.info(f"‚úÖ {config_name} –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ {config_path}.")
        else: self.logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {config_name} –∏–∑ {config_path}.")
        return data

    def adapt_prompts(self):
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –∞–¥–∞–ø—Ç–∞—Ü–∏—é –ø—Ä–æ–º–ø—Ç–æ–≤ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)."""
        if not self.adaptation_enabled: self.logger.info("üîÑ –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤ –æ—Ç–∫–ª—é—á–µ–Ω–∞."); return
        self.logger.info("üîÑ –ü—Ä–∏–º–µ–Ω—è—é –∞–¥–∞–ø—Ç–∞—Ü–∏—é –ø—Ä–æ–º–ø—Ç–æ–≤...");
        for key, value in self.adaptation_params.items(): self.logger.info(f"üîß –ü–∞—Ä–∞–º–µ—Ç—Ä '{key}' –æ–±–Ω–æ–≤–ª—ë–Ω –¥–æ {value}")

    def clear_generated_content(self):
        """–û—á–∏—â–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª —Å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏."""
        try:
            content_path_obj = Path(self.content_output_path)
            self.logger.info(f"üßπ –û—á–∏—Å—Ç–∫–∞ {content_path_obj.resolve()}") # –õ–æ–≥–∏—Ä—É–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å
            ensure_directory_exists(str(content_path_obj)) # –ü–µ—Ä–µ–¥–∞–µ–º —Å—Ç—Ä–æ–∫—É
            with open(content_path_obj, 'w', encoding='utf-8') as file: json.dump({}, file)
            self.logger.info("‚úÖ –õ–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –æ—á–∏—â–µ–Ω/—Å–æ–∑–¥–∞–Ω.")
        except PermissionError: handle_error("Clear Content Error", f"–ù–µ—Ç –ø—Ä–∞–≤ –Ω–∞ –∑–∞–ø–∏—Å—å: {self.content_output_path}", PermissionError())
        except Exception as e: handle_error("Clear Content Error", str(e), e)


    def load_tracker(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç—Ä–µ–∫–µ—Ä —Ç–µ–º –∏–∑ B2 –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞."""
        tracker_path_abs = self.tracker_path_abs; tracker_path_rel = self.tracker_path_rel
        failsafe_path_abs = self.failsafe_path_abs; bucket_name = self.b2_bucket_name
        os.makedirs(tracker_path_abs.parent, exist_ok=True); tracker_updated_locally = False
        if self.b2_client:
            try:
                self.logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ {tracker_path_rel} –∏–∑ B2...")
                timestamp_suffix = datetime.utcnow().strftime("%Y%m%d%H%M%S%f"); local_temp_tracker = f"tracker_temp_{timestamp_suffix}.json"
                ensure_directory_exists(local_temp_tracker) # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –ø–∞–ø–∫–∞ –¥–ª—è temp –µ—Å—Ç—å
                self.b2_client.download_file(bucket_name, tracker_path_rel, local_temp_tracker)
                shutil.copyfile(local_temp_tracker, str(tracker_path_abs)); os.remove(local_temp_tracker)
                self.logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω {tracker_path_rel} –∏–∑ B2.")
            except ClientError as e:
                 error_code = e.response.get('Error', {}).get('Code')
                 if error_code == 'NoSuchKey' or '404' in str(e): self.logger.warning(f"‚ö†Ô∏è {tracker_path_rel} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ B2.")
                 else: self.logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ B2 –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ç—Ä–µ–∫–µ—Ä–∞: {e}")
            except Exception as e: self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ç—Ä–µ–∫–µ—Ä –∏–∑ B2: {e}")
        else: self.logger.warning("‚ö†Ô∏è B2 –∫–ª–∏–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
        if not tracker_path_abs.exists():
            self.logger.warning(f"{tracker_path_abs} –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–æ–∑–¥–∞–Ω–∏–µ –∏–∑ {failsafe_path_abs}.")
            try:
                ensure_directory_exists(str(failsafe_path_abs.parent)) # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–ø–∫–∏ –¥–ª—è failsafe
                if not failsafe_path_abs.is_file(): raise FileNotFoundError(f"Failsafe —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {failsafe_path_abs}")
                with open(failsafe_path_abs, 'r', encoding='utf-8') as f_failsafe: failsafe_data = json.load(f_failsafe)
                tracker = {"all_focuses": failsafe_data.get("focuses", []), "used_focuses": [], "focus_data": {}}
                with open(tracker_path_abs, 'w', encoding='utf-8') as f_tracker: json.dump(tracker, f_tracker, ensure_ascii=False, indent=4)
                self.logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π {tracker_path_abs}."); tracker_updated_locally = True
            except FileNotFoundError: self.logger.error(f"‚ùå {failsafe_path_abs} –Ω–µ –Ω–∞–π–¥–µ–Ω!"); return {"all_focuses": [], "used_focuses": [], "focus_data": {}}
            except Exception as e: self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç—Ä–µ–∫–µ—Ä–∞: {e}"); return {"all_focuses": [], "used_focuses": [], "focus_data": {}}
        try:
            with open(tracker_path_abs, 'r', encoding='utf-8') as f: tracker = json.load(f)
            if "all_focuses" not in tracker: # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å—Ç–∞—Ä–æ–≥–æ —Ç—Ä–µ–∫–µ—Ä–∞
                self.logger.info("–û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç—Ä–µ–∫–µ—Ä–∞."); failsafe_data = {}
                if failsafe_path_abs.exists():
                     with open(failsafe_path_abs, 'r', encoding='utf-8') as f_failsafe: failsafe_data = json.load(f_failsafe)
                tracker["all_focuses"] = failsafe_data.get("focuses", []); tracker.setdefault("used_focuses", []); tracker.setdefault("focus_data", {})
                with open(tracker_path_abs, 'w', encoding='utf-8') as f_tracker: json.dump(tracker, f_tracker, ensure_ascii=False, indent=4)
                tracker_updated_locally = True
            if tracker_updated_locally: self.sync_tracker_to_b2(tracker_path_abs=tracker_path_abs, tracker_path_rel=tracker_path_rel)
            return tracker
        except json.JSONDecodeError: self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ JSON –≤ —Ç—Ä–µ–∫–µ—Ä–µ: {tracker_path_abs}."); return {"all_focuses": [], "used_focuses": [], "focus_data": {}}
        except Exception as e: self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ç—Ä–µ–∫–µ—Ä–∞ {tracker_path_abs}: {e}"); return {"all_focuses": [], "used_focuses": [], "focus_data": {}}

    def get_valid_focus_areas(self, tracker):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ñ–æ–∫—É—Å–æ–≤."""
        all_focuses = tracker.get("all_focuses", []); used_focuses = tracker.get("used_focuses", [])
        used_set = set(used_focuses); valid_focuses = [f for f in all_focuses if f not in used_set]
        self.logger.info(f"‚úÖ –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–æ–∫—É—Å—ã: {len(valid_focuses)} —à—Ç."); self.logger.debug(f"–ü–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫: {valid_focuses}")
        return valid_focuses

    def generate_topic(self, tracker):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –Ω–æ–≤—É—é —Ç–µ–º—É."""
        valid_focuses = self.get_valid_focus_areas(tracker)
        if not valid_focuses: raise ValueError("–í—Å–µ —Ñ–æ–∫—É—Å—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã.")
        selected_focus = random.choice(valid_focuses)
        self.logger.info(f"–í—ã–±—Ä–∞–Ω —Ñ–æ–∫—É—Å: {selected_focus}")
        used_labels = tracker.get("focus_data", {}).get(selected_focus, [])
        exclusions_str = ", ".join(used_labels) if used_labels else "–Ω–µ—Ç"

        prompt_config_key = "content.topic"
        prompt_template = self._get_prompt_template(prompt_config_key)
        if not prompt_template: raise ValueError(f"–ü—Ä–æ–º–ø—Ç {prompt_config_key} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        prompt = prompt_template.format(focus_areas=selected_focus, exclusions=exclusions_str)

        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é call_openai
            topic_data = call_openai(prompt,
                                     prompt_config_key=prompt_config_key,
                                     use_json_mode=True,
                                     config_manager_instance=self.config,
                                     prompts_config_data_instance=self.prompts_config_data)

            if not topic_data: raise ValueError("call_openai –Ω–µ –≤–µ—Ä–Ω—É–ª –æ—Ç–≤–µ—Ç –¥–ª—è —Ç–µ–º—ã.")
            # topic_data —É–∂–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º, –µ—Å–ª–∏ use_json_mode=True –∏ –ø–∞—Ä—Å–∏–Ω–≥ —É—Å–ø–µ—à–µ–Ω

            full_topic = topic_data.get("full_topic"); short_topic = topic_data.get("short_topic")
            if not full_topic or not short_topic: raise ValueError(f"–û—Ç–≤–µ—Ç –¥–ª—è —Ç–µ–º—ã –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª—é—á–∏: {topic_data}")
            self.logger.info(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞ —Ç–µ–º–∞: '{full_topic}' (–Ø—Ä–ª—ã–∫: '{short_topic}')")
            self.update_tracker(selected_focus, short_topic, tracker)
            self.save_to_generated_content("topic", {"full_topic": full_topic, "short_topic": short_topic})
            content_metadata = {"theme": "tragic" if "(—Ç)" in selected_focus else "normal"}
            return full_topic, content_metadata
        except Exception as e: self.logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–º—ã: {e}", exc_info=True); raise

    def update_tracker(self, focus, short_topic, tracker):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ —Ç—Ä–µ–∫–µ—Ä–∞ –≤ –ø–∞–º—è—Ç–∏ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –µ–≥–æ."""
        used_focuses = tracker.get("used_focuses", []); focus_data = tracker.get("focus_data", {})
        if focus in used_focuses: used_focuses.remove(focus)
        used_focuses.insert(0, focus); tracker["used_focuses"] = used_focuses[:15]
        focus_labels = focus_data.setdefault(focus, [])
        if short_topic in focus_labels: focus_labels.remove(short_topic)
        focus_labels.insert(0, short_topic); focus_data[focus] = focus_labels[:5]
        tracker["focus_data"] = focus_data
        self.save_topics_tracker(tracker)
        self.sync_tracker_to_b2(tracker_path_abs=self.tracker_path_abs, tracker_path_rel=self.tracker_path_rel)

    def save_topics_tracker(self, tracker):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç—Ä–µ–∫–µ—Ä –≤ –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª."""
        try:
            ensure_directory_exists(str(self.tracker_path_abs.parent)) # –ò—Å–ø–æ–ª—å–∑—É–µ–º parent
            with open(self.tracker_path_abs, "w", encoding="utf-8") as file: json.dump(tracker, file, ensure_ascii=False, indent=4)
            self.logger.info(f"–¢—Ä–µ–∫–µ—Ä —Ç–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {self.tracker_path_abs}")
        except Exception as e: self.logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç—Ä–µ–∫–µ—Ä–∞: {e}")

    def sync_tracker_to_b2(self, tracker_path_abs, tracker_path_rel):
        """–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–π —Ç—Ä–µ–∫–µ—Ä —Å B2."""
        if not self.b2_client: self.logger.warning("B2 –∫–ª–∏–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω."); return
        if not tracker_path_abs.is_file(): self.logger.warning(f"–õ–æ–∫–∞–ª—å–Ω—ã–π —Ç—Ä–µ–∫–µ—Ä {tracker_path_abs} –Ω–µ –Ω–∞–π–¥–µ–Ω."); return # –ü—Ä–æ–≤–µ—Ä–∫–∞ is_file
        try:
            self.logger.info(f"–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è {tracker_path_abs} —Å B2 –∫–∞–∫ {tracker_path_rel}...")
            self.b2_client.upload_file(str(tracker_path_abs), self.b2_bucket_name, tracker_path_rel)
            self.logger.info(f"‚úÖ {tracker_path_rel} —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω —Å B2.")
        except Exception as e: self.logger.error(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ç—Ä–µ–∫–µ—Ä {tracker_path_rel} –≤ B2: {e}")

    # request_openai –£–î–ê–õ–ï–ù–ê, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è call_openai

    def _get_prompt_template(self, prompt_config_key: str) -> str | None:
        """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ–º–ø—Ç–∞."""
        if not self.prompts_config_data: self.logger.error("‚ùå –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞."); return None
        keys = prompt_config_key.split('.')
        prompt_settings = self.prompts_config_data
        try:
            for key in keys: prompt_settings = prompt_settings[key]
            template = prompt_settings.get('template')
            if not template: self.logger.error(f"–®–∞–±–ª–æ–Ω 'template' –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è '{prompt_config_key}'")
            return template
        except (KeyError, TypeError): self.logger.error(f"–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –∫–ª—é—á—É/—Å—Ç—Ä—É–∫—Ç—É—Ä–µ '{prompt_config_key}'"); return None

    def generate_sarcasm(self, text, content_data={}):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–∞—Ä–∫–∞—Å—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π."""
        if not self.config.get('SARCASM.enabled', True) or not self.config.get('SARCASM.comment_enabled', True):
            self.logger.info("üîï –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞."); return None
        prompt_key_suffix = "tragic_comment" if content_data.get("theme") == "tragic" else "comment"
        prompt_config_key = f"sarcasm.{prompt_key_suffix}"
        prompt_template = self._get_prompt_template(prompt_config_key)
        if not prompt_template: return None
        prompt = prompt_template.format(text=text)
        self.logger.info(f"–ó–∞–ø—Ä–æ—Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è (–∫–ª—é—á: {prompt_config_key})...")
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é call_openai
            comment = call_openai(prompt,
                                  prompt_config_key=prompt_config_key,
                                  use_json_mode=False, # –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π - —Å—Ç—Ä–æ–∫–∞
                                  config_manager_instance=self.config,
                                  prompts_config_data_instance=self.prompts_config_data)
            if comment: self.logger.info(f"‚úÖ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: {comment}")
            else: self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è ({prompt_config_key}).")
            return comment
        except Exception as e: self.logger.error(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è: {e}"); return None

    def generate_sarcasm_poll(self, text, content_data={}):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–∞—Ä–∫–∞—Å—Ç–∏—á–µ—Å–∫–∏–π –æ–ø—Ä–æ—Å."""
        if not self.config.get('SARCASM.enabled', True) or not self.config.get('SARCASM.poll_enabled', True):
            self.logger.info("üîï –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø—Ä–æ—Å–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞."); return {}
        prompt_key_suffix = "tragic_poll" if content_data.get("theme") == "tragic" else "poll"
        prompt_config_key = f"sarcasm.{prompt_key_suffix}"
        prompt_template = self._get_prompt_template(prompt_config_key)
        if not prompt_template: return {}
        prompt = prompt_template.format(text=text)
        self.logger.info(f"–ó–∞–ø—Ä–æ—Å –æ–ø—Ä–æ—Å–∞ (–∫–ª—é—á: {prompt_config_key})... JSON.")
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é call_openai
            poll_data = call_openai(prompt,
                                    prompt_config_key=prompt_config_key,
                                    use_json_mode=True, # –û–ø—Ä–æ—Å - JSON
                                    config_manager_instance=self.config,
                                    prompts_config_data_instance=self.prompts_config_data)

            if not poll_data: self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–ø—Ä–æ—Å–∞ ({prompt_config_key})."); return {}
            # poll_data —É–∂–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º

            if isinstance(poll_data, dict) and "question" in poll_data and "options" in poll_data and isinstance(poll_data["options"], list) and len(poll_data["options"]) == 3:
                self.logger.info("‚úÖ –û–ø—Ä–æ—Å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω."); poll_data["question"] = str(poll_data["question"]).strip(); poll_data["options"] = [str(opt).strip() for opt in poll_data["options"]]
                return poll_data
            else: self.logger.error(f"‚ùå –°—Ç—Ä—É–∫—Ç—É—Ä–∞ JSON –æ–ø—Ä–æ—Å–∞ –Ω–µ–≤–µ—Ä–Ω–∞: {poll_data}"); return {}
        except Exception as e: self.logger.error(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –æ–ø—Ä–æ—Å–∞: {e}"); return {}

    def save_to_generated_content(self, stage, data):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –ª–æ–∫–∞–ª—å–Ω—ã–π JSON —Ñ–∞–π–ª."""
        try:
            if not self.content_output_path: raise ValueError("‚ùå self.content_output_path –Ω–µ –∑–∞–¥–∞–Ω!")
            content_path_obj = Path(self.content_output_path)
            self.logger.debug(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ {content_path_obj.resolve()}, —ç—Ç–∞–ø: {stage}")
            ensure_directory_exists(str(content_path_obj)); result_data = {}
            if content_path_obj.exists():
                try:
                    if content_path_obj.stat().st_size > 0:
                        with open(content_path_obj, 'r', encoding='utf-8') as file: result_data = json.load(file)
                    else: self.logger.warning(f"‚ö†Ô∏è –§–∞–π–ª {content_path_obj} –ø—É—Å—Ç."); result_data = {}
                except json.JSONDecodeError: self.logger.warning(f"‚ö†Ô∏è –§–∞–π–ª {content_path_obj} –ø–æ–≤—Ä–µ–∂–¥–µ–Ω."); result_data = {}
                except Exception as read_err: self.logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {content_path_obj}: {read_err}"); result_data = {}
            result_data["timestamp"] = datetime.utcnow().isoformat(); result_data[stage] = data
            with open(content_path_obj, 'w', encoding='utf-8') as file: json.dump(result_data, file, ensure_ascii=False, indent=4)
            self.logger.debug(f"‚úÖ –õ–æ–∫–∞–ª—å–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–æ –¥–ª—è —ç—Ç–∞–ø–∞: {stage}")
        except Exception as e: handle_error("Save Content Error", f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ {self.content_output_path}: {str(e)}", e)

    def critique_content(self, content, topic):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∫—Ä–∏—Ç–∏–∫—É —Ç–µ–∫—Å—Ç–∞ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)."""
        if not self.config.get('CONTENT.critique.enabled', False): self.logger.info("üîï –ö—Ä–∏—Ç–∏–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞."); return "–ö—Ä–∏—Ç–∏–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞."
        if not content: self.logger.warning("–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∫—Ä–∏—Ç–∏–∫–∏."); return "–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∫—Ä–∏—Ç–∏–∫–∏."
        try:
            self.logger.info("üîÑ –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∫—Ä–∏—Ç–∏–∫–∞...")
            prompt_config_key = "content.critique"
            prompt_template = self._get_prompt_template(prompt_config_key)
            if not prompt_template or prompt_template == "...": self.logger.error(f"–ü—Ä–æ–º–ø—Ç {prompt_config_key} –Ω–µ –Ω–∞–π–¥–µ–Ω."); return "–ü—Ä–æ–º–ø—Ç –∫—Ä–∏—Ç–∏–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω."
            prompt = prompt_template.format(content=content, topic=topic)
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é call_openai
            critique = call_openai(prompt,
                                   prompt_config_key=prompt_config_key,
                                   use_json_mode=False, # –ö—Ä–∏—Ç–∏–∫–∞ - —Å—Ç—Ä–æ–∫–∞
                                   config_manager_instance=self.config,
                                   prompts_config_data_instance=self.prompts_config_data)
            if critique: self.logger.info("‚úÖ –ö—Ä–∏—Ç–∏–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
            else: self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∫—Ä–∏—Ç–∏–∫–∏ ({prompt_config_key}).")
            return critique if critique else "–ö—Ä–∏—Ç–∏–∫–∞ –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å –æ—à–∏–±–∫–æ–π."
        except Exception as e: self.logger.error(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –∫—Ä–∏—Ç–∏–∫–µ: {e}"); return "–ö—Ä–∏—Ç–∏–∫–∞ –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å –æ—à–∏–±–∫–æ–π."

    def format_list_for_prompt(self, items: list | dict, use_weights=False) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–ª–∏ —Å–ª–æ–≤–∞—Ä—å —Å–ø–∏—Å–∫–æ–≤ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ –≤ –ø—Ä–æ–º–ø—Ç."""
        lines = [];
        if isinstance(items, list):
            if not items: return "- (–°–ø–∏—Å–æ–∫ –ø—É—Å—Ç)"
            for item in items:
                if use_weights and isinstance(item, dict) and 'value' in item and 'weight' in item: lines.append(f"* {item['value']} (–í–µ—Å: {item['weight']})")
                elif isinstance(item, str): lines.append(f"* {item}")
                elif isinstance(item, dict) and 'value' in item: lines.append(f"* {item['value']}")
        elif isinstance(items, dict):
             if not items: return "- (–°–ª–æ–≤–∞—Ä—å –ø—É—Å—Ç)"; is_dict_of_lists = all(isinstance(v, list) for v in items.values())
             for category, cat_items in items.items():
                 if is_dict_of_lists:
                     if lines: lines.append(""); lines.append(f"  –ö–∞—Ç–µ–≥–æ—Ä–∏—è '{category}':")
                     formatted_sublist = self.format_list_for_prompt(cat_items, use_weights=(use_weights and category == 'main'))
                     if formatted_sublist != "- (–°–ø–∏—Å–æ–∫ –ø—É—Å—Ç)": indented_lines = [f"    {line}" if line.strip() else line for line in formatted_sublist.split('\n')]; lines.extend(indented_lines)
                 elif isinstance(cat_items, list):
                      lines.append(f"* {category}:")
                      formatted_sublist = self.format_list_for_prompt(cat_items, use_weights=False)
                      if formatted_sublist != "- (–°–ø–∏—Å–æ–∫ –ø—É—Å—Ç)": indented_lines = [f"    {line}" if line.strip() else line for line in formatted_sublist.split('\n')]; lines.extend(indented_lines)
                 else: lines.append(f"* {category}: {cat_items}")
        else: return "- (–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö)"
        return "\n".join(lines).strip()

    def run(self, generation_id):
        """–û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ ID."""
        self.logger.info(f"--- –ó–∞–ø—É—Å–∫ ContentGenerator.run –¥–ª—è ID: {generation_id} ---")
        if not generation_id: raise ValueError("generation_id –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º.")
        if not self.creative_config_data or not self.prompts_config_data: raise RuntimeError("–ö–æ–Ω—Ñ–∏–≥–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")

        try:
            # –®–∞–≥ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞
            self.adapt_prompts(); self.clear_generated_content()
            # –®–∞–≥ 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¢–µ–º—ã
            tracker = self.load_tracker(); topic, content_data = self.generate_topic(tracker)
            # –®–∞–≥ 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¢–µ–∫—Å—Ç–∞ (RU)
            text_initial = ""; generate_text_enabled = self.config.get('CONTENT.text.enabled', True); generate_tragic_text_enabled = self.config.get('CONTENT.tragic_text.enabled', True)
            if (content_data.get("theme") == "tragic" and generate_tragic_text_enabled) or (content_data.get("theme") != "tragic" and generate_text_enabled):
                prompt_key_suffix = "tragic_text" if content_data.get("theme") == "tragic" else "text"; prompt_config_key = f"content.{prompt_key_suffix}"
                prompt_template = self._get_prompt_template(prompt_config_key)
                if prompt_template:
                     # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é call_openai
                     text_initial = call_openai(prompt_template.format(topic=topic),
                                                prompt_config_key=prompt_config_key,
                                                use_json_mode=False, # –¢–µ–∫—Å—Ç - —Å—Ç—Ä–æ–∫–∞
                                                config_manager_instance=self.config,
                                                prompts_config_data_instance=self.prompts_config_data)
                     if text_initial: self.logger.info(f"–¢–µ–∫—Å—Ç: {text_initial[:100]}..."); self.save_to_generated_content("text", {"text": text_initial})
                     else: self.logger.warning(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ ({prompt_config_key}) –Ω–µ —É–¥–∞–ª–∞—Å—å.")
                else: self.logger.warning(f"–ü—Ä–æ–º–ø—Ç {prompt_config_key} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
            else: self.logger.info(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ (—Ç–µ–º–∞: {content_data.get('theme')}) –æ—Ç–∫–ª—é—á–µ–Ω–∞.")
            # –®–∞–≥ 4: –ö—Ä–∏—Ç–∏–∫–∞
            critique_result = self.critique_content(text_initial, topic); self.save_to_generated_content("critique", {"critique": critique_result})
            # –®–∞–≥ 5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –°–∞—Ä–∫–∞–∑–º–∞ (RU)
            sarcastic_comment = None; sarcastic_poll = {}
            if text_initial: sarcastic_comment = self.generate_sarcasm(text_initial, content_data); sarcastic_poll = self.generate_sarcasm_poll(text_initial, content_data)
            self.save_to_generated_content("sarcasm", {"comment": sarcastic_comment, "poll": sarcastic_poll})

            # –®–∞–≥ 6: –ú–Ω–æ–≥–æ—à–∞–≥–æ–≤–∞—è –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ë—Ä–∏—Ñ–∞ –∏ –ü—Ä–æ–º–ø—Ç–æ–≤ (EN) + –ü–µ—Ä–µ–≤–æ–¥ (RU)
            self.logger.info("--- –ó–∞–ø—É—Å–∫ –º–Ω–æ–≥–æ—à–∞–≥–æ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ ---")
            creative_brief, script_en, frame_description_en, final_mj_prompt_en, final_runway_prompt_en = None, None, None, None, None
            script_ru, frame_description_ru, final_mj_prompt_ru, final_runway_prompt_ru = None, None, None, None
            enable_russian_translation = self.config.get("WORKFLOW.enable_russian_translation", False)
            self.logger.info(f"–ü–µ—Ä–µ–≤–æ–¥ {'–í–ö–õ–Æ–ß–ï–ù' if enable_russian_translation else '–û–¢–ö–õ–Æ–ß–ï–ù'}.")

            try:
                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–ø–∏—Å–∫–æ–≤
                moods_list_str = self.format_list_for_prompt(self.creative_config_data.get("moods", []), use_weights=True)
                arcs_list_str = self.format_list_for_prompt(self.creative_config_data.get("emotional_arcs", []))
                main_prompts_list = self.creative_config_data.get("creative_prompts", {}).get("main", [])
                prompts_list_str = self.format_list_for_prompt(main_prompts_list, use_weights=True)
                perspectives_list_str = self.format_list_for_prompt(self.creative_config_data.get("perspective_types", []))
                metaphors_list_str = self.format_list_for_prompt(self.creative_config_data.get("visual_metaphor_types", []))
                directors_list_str = self.format_list_for_prompt(self.creative_config_data.get("director_styles", []))
                artists_list_str = self.format_list_for_prompt(self.creative_config_data.get("artist_styles", []))

                # –®–∞–≥ 6.1: –Ø–¥—Ä–æ
                self.logger.info("--- –®–∞–≥ 6.1: –Ø–¥—Ä–æ ---"); prompt_key1 = "multi_step.step1_core"; tmpl1 = self._get_prompt_template(prompt_key1);
                if not tmpl1: raise ValueError(f"{prompt_key1} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
                prompt1 = tmpl1.format(input_text=topic, moods_list_str=moods_list_str, arcs_list_str=arcs_list_str)
                core_brief = call_openai(prompt1, prompt_config_key=prompt_key1, use_json_mode=True, config_manager_instance=self.config, prompts_config_data_instance=self.prompts_config_data)
                if not core_brief: raise ValueError("–®–∞–≥ 6.1 –Ω–µ —É–¥–∞–ª—Å—è."); # core_brief —É–∂–µ —Å–ª–æ–≤–∞—Ä—å
                if not all(k in core_brief for k in ["chosen_type", "chosen_value", "justification"]): raise ValueError(f"–®–∞–≥ 6.1: –Ω–µ–≤–µ—Ä–Ω—ã–π JSON {core_brief}.")

                # –®–∞–≥ 6.2: –î—Ä–∞–π–≤–µ—Ä
                self.logger.info("--- –®–∞–≥ 6.2: –î—Ä–∞–π–≤–µ—Ä ---"); prompt_key2 = "multi_step.step2_driver"; tmpl2 = self._get_prompt_template(prompt_key2);
                if not tmpl2: raise ValueError(f"{prompt_key2} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
                prompt2 = tmpl2.format(input_text=topic, chosen_emotional_core_json=json.dumps(core_brief, ensure_ascii=False, indent=2), prompts_list_str=prompts_list_str, perspectives_list_str=perspectives_list_str, metaphors_list_str=metaphors_list_str)
                driver_brief = call_openai(prompt2, prompt_config_key=prompt_key2, use_json_mode=True, config_manager_instance=self.config, prompts_config_data_instance=self.prompts_config_data)
                if not driver_brief: raise ValueError("–®–∞–≥ 6.2 –Ω–µ —É–¥–∞–ª—Å—è."); # driver_brief —É–∂–µ —Å–ª–æ–≤–∞—Ä—å
                if not all(k in driver_brief for k in ["chosen_driver_type", "chosen_driver_value", "justification"]): raise ValueError(f"–®–∞–≥ 6.2: –Ω–µ–≤–µ—Ä–Ω—ã–π JSON {driver_brief}.")

                # –®–∞–≥ 6.3: –≠—Å—Ç–µ—Ç–∏–∫–∞
                self.logger.info("--- –®–∞–≥ 6.3: –≠—Å—Ç–µ—Ç–∏–∫–∞ ---"); prompt_key3 = "multi_step.step3_aesthetic"; tmpl3 = self._get_prompt_template(prompt_key3);
                if not tmpl3: raise ValueError(f"{prompt_key3} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
                prompt3 = tmpl3.format(input_text=topic, chosen_emotional_core_json=json.dumps(core_brief, ensure_ascii=False, indent=2), chosen_driver_json=json.dumps(driver_brief, ensure_ascii=False, indent=2), directors_list_str=directors_list_str, artists_list_str=artists_list_str)
                aesthetic_brief = call_openai(prompt3, prompt_config_key=prompt_key3, use_json_mode=True, config_manager_instance=self.config, prompts_config_data_instance=self.prompts_config_data)
                if not aesthetic_brief: raise ValueError("–®–∞–≥ 6.3 –Ω–µ —É–¥–∞–ª—Å—è."); # aesthetic_brief —É–∂–µ —Å–ª–æ–≤–∞—Ä—å
                # –í–∞–ª–∏–¥–∞—Ü–∏—è aesthetic_brief (–æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
                valid_step3 = False
                if isinstance(aesthetic_brief, dict):
                    style_needed = aesthetic_brief.get("style_needed", False); base_keys_exist = all(k in aesthetic_brief for k in ["style_needed", "chosen_style_type", "chosen_style_value", "style_keywords", "justification"])
                    if base_keys_exist:
                        if not style_needed:
                            if all(aesthetic_brief.get(k) is None for k in ["chosen_style_type", "chosen_style_value", "style_keywords", "justification"]): valid_step3 = True
                            else: self.logger.warning(f"–®–∞–≥ 6.3: style_needed=false, –Ω–æ –∫–ª—é—á–∏ –Ω–µ null. –ò—Å–ø—Ä–∞–≤–ª—è–µ–º."); aesthetic_brief.update({k:None for k in ["chosen_style_type", "chosen_style_value", "style_keywords", "justification"]}); valid_step3 = True
                        else:
                            if all([aesthetic_brief.get("chosen_style_type"), aesthetic_brief.get("chosen_style_value"), isinstance(aesthetic_brief.get("style_keywords"), list), aesthetic_brief.get("justification")]): valid_step3 = True
                            else: logger.error(f"–®–∞–≥ 6.3: style_needed=true, –Ω–æ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã.")
                    else: logger.error(f"–®–∞–≥ 6.3: –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –±–∞–∑–æ–≤—ã–µ –∫–ª—é—á–∏.")
                else: logger.error(f"–®–∞–≥ 6.3: –û—Ç–≤–µ—Ç –Ω–µ —Å–ª–æ–≤–∞—Ä—å.")
                if not valid_step3: raise ValueError("–®–∞–≥ 6.3: –Ω–µ–≤–µ—Ä–Ω—ã–π JSON.")


                # –°–±–æ—Ä–∫–∞ –ë—Ä–∏—Ñ–∞
                creative_brief = {"core": core_brief, "driver": driver_brief, "aesthetic": aesthetic_brief}; self.logger.info("--- –®–∞–≥ 6.4: –ë—Ä–∏—Ñ –°–æ–±—Ä–∞–Ω ---"); self.logger.debug(f"–ë—Ä–∏—Ñ: {json.dumps(creative_brief, ensure_ascii=False, indent=2)}"); self.save_to_generated_content("creative_brief", creative_brief)

                # –®–∞–≥ 6.5: –°—Ü–µ–Ω–∞—Ä–∏–π –∏ –û–ø–∏—Å–∞–Ω–∏–µ (EN)
                self.logger.info("--- –®–∞–≥ 6.5: –°—Ü–µ–Ω–∞—Ä–∏–π –∏ –û–ø–∏—Å–∞–Ω–∏–µ (EN) ---"); prompt_key5 = "multi_step.step5_script_frame"; tmpl5 = self._get_prompt_template(prompt_key5);
                if not tmpl5: raise ValueError(f"{prompt_key5} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
                prompt5 = tmpl5.format(input_text=topic, creative_brief_json=json.dumps(creative_brief, ensure_ascii=False, indent=2))
                script_frame_data = call_openai(prompt5, prompt_config_key=prompt_key5, use_json_mode=True, config_manager_instance=self.config, prompts_config_data_instance=self.prompts_config_data)
                if not script_frame_data: raise ValueError("–®–∞–≥ 6.5 –Ω–µ —É–¥–∞–ª—Å—è."); # script_frame_data —É–∂–µ —Å–ª–æ–≤–∞—Ä—å
                if not all(k in script_frame_data for k in ["script", "first_frame_description"]): raise ValueError(f"–®–∞–≥ 6.5: –Ω–µ–≤–µ—Ä–Ω—ã–π JSON {script_frame_data}.")
                script_en = script_frame_data["script"]; frame_description_en = script_frame_data["first_frame_description"]
                self.logger.info(f"–°—Ü–µ–Ω–∞—Ä–∏–π (EN): {script_en[:100]}..."); self.logger.info(f"–û–ø–∏—Å–∞–Ω–∏–µ (EN): {frame_description_en[:100]}..."); self.save_to_generated_content("script_frame_en", {"script": script_en, "first_frame_description": frame_description_en})

                # –®–∞–≥ 6.6a: MJ –ü—Ä–æ–º–ø—Ç (EN)
                self.logger.info("--- –®–∞–≥ 6.6a: MJ –ü—Ä–æ–º–ø—Ç (EN) ---"); mj_params_cfg = self.config.get("IMAGE_GENERATION", {}); aspect_ratio_str = mj_params_cfg.get("output_size", "16:9").replace('x', ':').replace('√ó', ':'); version_str = str(mj_params_cfg.get("midjourney_version", "7.0")); style_str = mj_params_cfg.get("midjourney_style", None)
                mj_parameters_json_for_prompt = json.dumps({"aspect_ratio": aspect_ratio_str, "version": version_str, "style": style_str}, ensure_ascii=False); style_parameter_str_for_prompt = f" --style {style_str}" if style_str else ""
                prompt_key6a = "multi_step.step6a_mj_adapt"; tmpl6a = self._get_prompt_template(prompt_key6a);
                if not tmpl6a: raise ValueError(f"{prompt_key6a} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
                prompt6a = tmpl6a.format(first_frame_description=frame_description_en, creative_brief_json=json.dumps(creative_brief, ensure_ascii=False, indent=2), script=script_en, input_text=topic, mj_parameters_json=mj_parameters_json_for_prompt, aspect_ratio=aspect_ratio_str, version=version_str, style_parameter_str=style_parameter_str_for_prompt)
                mj_prompt_data = call_openai(prompt6a, prompt_config_key=prompt_key6a, use_json_mode=True, config_manager_instance=self.config, prompts_config_data_instance=self.prompts_config_data)
                if not mj_prompt_data: raise ValueError("–®–∞–≥ 6.6a –Ω–µ —É–¥–∞–ª—Å—è."); # mj_prompt_data —É–∂–µ —Å–ª–æ–≤–∞—Ä—å
                if "final_mj_prompt" not in mj_prompt_data: raise ValueError(f"–®–∞–≥ 6.6a: –Ω–µ–≤–µ—Ä–Ω—ã–π JSON {mj_prompt_data}.")
                final_mj_prompt_en = mj_prompt_data["final_mj_prompt"]; self.logger.info(f"MJ –ø—Ä–æ–º–ø—Ç (EN, V{version_str}): {final_mj_prompt_en}"); self.save_to_generated_content("final_mj_prompt_en", {"final_mj_prompt": final_mj_prompt_en})

                # –®–∞–≥ 6.6b: Runway –ü—Ä–æ–º–ø—Ç (EN)
                self.logger.info("--- –®–∞–≥ 6.6b: Runway –ü—Ä–æ–º–ø—Ç (EN) ---"); prompt_key6b = "multi_step.step6b_runway_adapt"; tmpl6b = self._get_prompt_template(prompt_key6b);
                if not tmpl6b: raise ValueError(f"{prompt_key6b} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
                prompt6b = tmpl6b.format(script=script_en, creative_brief_json=json.dumps(creative_brief, ensure_ascii=False, indent=2), input_text=topic)
                runway_prompt_data = call_openai(prompt6b, prompt_config_key=prompt_key6b, use_json_mode=True, config_manager_instance=self.config, prompts_config_data_instance=self.prompts_config_data)
                if not runway_prompt_data: raise ValueError("–®–∞–≥ 6.6b –Ω–µ —É–¥–∞–ª—Å—è."); # runway_prompt_data —É–∂–µ —Å–ª–æ–≤–∞—Ä—å
                if "final_runway_prompt" not in runway_prompt_data: raise ValueError(f"–®–∞–≥ 6.6b: –Ω–µ–≤–µ—Ä–Ω—ã–π JSON {runway_prompt_data}.")
                final_runway_prompt_en = runway_prompt_data["final_runway_prompt"]; self.logger.info(f"Runway –ø—Ä–æ–º–ø—Ç (EN): {final_runway_prompt_en}"); self.save_to_generated_content("final_runway_prompt_en", {"final_runway_prompt": final_runway_prompt_en})

                # –®–∞–≥ 6.6c: –ü–µ—Ä–µ–≤–æ–¥ (RU)
                if enable_russian_translation:
                    self.logger.info("--- –®–∞–≥ 6.6c: –ü–µ—Ä–µ–≤–æ–¥ (RU) ---")
                    if all([script_en, frame_description_en, final_mj_prompt_en, final_runway_prompt_en]):
                        prompt_key6c = "multi_step.step6c_translate"; tmpl6c = self._get_prompt_template(prompt_key6c);
                        if not tmpl6c: raise ValueError(f"{prompt_key6c} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
                        prompt6c = tmpl6c.format(script_en=script_en, frame_description_en=frame_description_en, mj_prompt_en=final_mj_prompt_en, runway_prompt_en=final_runway_prompt_en)
                        translations = call_openai(prompt6c, prompt_config_key=prompt_key6c, use_json_mode=True, config_manager_instance=self.config, prompts_config_data_instance=self.prompts_config_data)
                        if translations: # translations —É–∂–µ —Å–ª–æ–≤–∞—Ä—å
                            script_ru = translations.get("script_ru"); frame_description_ru = translations.get("first_frame_description_ru"); final_mj_prompt_ru = translations.get("final_mj_prompt_ru"); final_runway_prompt_ru = translations.get("final_runway_prompt_ru")
                            if all([script_ru, frame_description_ru, final_mj_prompt_ru, final_runway_prompt_ru]): self.logger.info("‚úÖ –ü–µ—Ä–µ–≤–æ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω."); self.save_to_generated_content("translations_ru", translations)
                            else: self.logger.error(f"–®–∞–≥ 6.6c: –ù–µ –≤—Å–µ –ø–æ–ª—è –ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ã. {translations}"); translations = None
                        else: self.logger.error("–®–∞–≥ 6.6c –Ω–µ —É–¥–∞–ª—Å—è."); translations = None
                    else: self.logger.error("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞."); translations = None
                else: self.logger.info("–ü–µ—Ä–µ–≤–æ–¥ –ø—Ä–æ–ø—É—â–µ–Ω.")

            except (json.JSONDecodeError, ValueError, RuntimeError) as step6_err: # –î–æ–±–∞–≤–∏–ª RuntimeError
                 self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —à–∞–≥–∞ 6: {step6_err}.")
                 # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –∏–∑-–∑–∞ OpenAI –∫–ª–∏–µ–Ω—Ç–∞, –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –≤—ã—à–µ
                 if isinstance(step6_err, RuntimeError) and "OpenAI client" in str(step6_err):
                     raise
            except Exception as script_err: self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —à–∞–≥–∞ 6: {script_err}", exc_info=True)

            # –®–∞–≥ 7: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ B2
            self.logger.info("–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è –¥–ª—è B2...")
            complete_content_dict = {
                "topic": topic, "content": text_initial.strip() if text_initial else "",
                "sarcasm": {"comment": sarcastic_comment, "poll": sarcastic_poll},
                "script": script_en, "first_frame_description": frame_description_en,
                "creative_brief": creative_brief, "final_mj_prompt": final_mj_prompt_en,
                "final_runway_prompt": final_runway_prompt_en,
                "script_ru": script_ru, "first_frame_description_ru": frame_description_ru,
                "final_mj_prompt_ru": final_mj_prompt_ru, "final_runway_prompt_ru": final_runway_prompt_ru,
            }
            complete_content_dict = {k: v for k, v in complete_content_dict.items() if v is not None}
            self.logger.debug(f"–ò—Ç–æ–≥–æ–≤—ã–π —Å–ª–æ–≤–∞—Ä—å: {json.dumps(complete_content_dict, ensure_ascii=False, indent=2)}")
            self.logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ B2 –¥–ª—è ID {generation_id}...")
            if not save_content_to_b2("666/", complete_content_dict, generation_id, self.config):
                raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Ç–æ–≥–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –≤ B2 –¥–ª—è ID {generation_id}")

            # –®–∞–≥ 8: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ config_midjourney.json
            self.logger.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ config_midjourney.json –¥–ª—è ID: {generation_id}...")
            try:
                s3_client_mj = self.b2_client
                if not s3_client_mj: raise ConnectionError("B2 –∫–ª–∏–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
                config_mj_remote_path = self.config.get('FILE_PATHS.config_midjourney', 'config/config_midjourney.json')
                timestamp_suffix = datetime.utcnow().strftime("%Y%m%d%H%M%S%f")
                config_mj_local_path = f"config_midjourney_{generation_id}_temp_{timestamp_suffix}.json"
                bucket_name = self.b2_bucket_name
                ensure_directory_exists(config_mj_local_path) # –ü–∞–ø–∫–∞ –¥–ª—è temp
                config_mj = load_b2_json(s3_client_mj, bucket_name, config_mj_remote_path, config_mj_local_path, default_value={})
                if config_mj is None: config_mj = {}
                config_mj['generation'] = True; config_mj['midjourney_task'] = None; config_mj['midjourney_results'] = {}; config_mj['status'] = None
                self.logger.info("–î–∞–Ω–Ω—ã–µ –¥–ª—è config_midjourney.json –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã.")
                if not save_b2_json(s3_client_mj, bucket_name, config_mj_remote_path, config_mj_local_path, config_mj):
                     raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å config_mj!")
                else: self.logger.info(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π {config_mj_remote_path} –∑–∞–≥—Ä—É–∂–µ–Ω –≤ B2.")
            except Exception as e: self.logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å config_midjourney.json: {e}", exc_info=True); raise Exception("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ñ–ª–∞–≥ generation: true") from e

            self.logger.info(f"‚úÖ ContentGenerator.run —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω –¥–ª—è ID {generation_id}.")

        except Exception as e: self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ ContentGenerator.run –¥–ª—è ID {generation_id}: {e}", exc_info=True); raise

# --- –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ ---
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Generate content for a specific ID.')
    parser.add_argument('--generation_id', type=str, required=True, help='The generation ID.')
    args = parser.parse_args()
    generation_id_main = args.generation_id
    if not generation_id_main: logger.critical("generation_id –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω!"); sys.exit(1)
    logger.info(f"--- –ó–∞–ø—É—Å–∫ generate_content.py –¥–ª—è ID: {generation_id_main} ---")
    exit_code = 1
    try:
        generator = ContentGenerator(); generator.run(generation_id_main)
        logger.info(f"--- –°–∫—Ä–∏–ø—Ç generate_content.py —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω –¥–ª—è ID: {generation_id_main} ---")
        exit_code = 0
    except Exception as main_err:
        logger.error(f"!!! –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê generate_content.py –¥–ª—è ID {generation_id_main} !!!")
        # –õ–æ–≥–∏—Ä—É–µ–º —Å–∞–º–æ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è –±–æ–ª—å—à–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        logger.exception(main_err)
    finally: logger.info(f"--- –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ generate_content.py —Å –∫–æ–¥–æ–º –≤—ã—Ö–æ–¥–∞: {exit_code} ---"); sys.exit(exit_code)
